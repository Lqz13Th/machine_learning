{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebae9d6-ac6f-4a2f-aaa0-1143a629b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "def lag_exprs(col: str, lag: int) -> pl.Expr:\n",
    "    return pl.col(col).shift(lag).alias(f\"{col}_lag_{lag}\")\n",
    "\n",
    "def diff_expr(col: str, lag: int = 1) -> pl.Expr:\n",
    "    return (pl.col(col) - pl.col(col).shift(lag)).alias(f\"{col}_diff_{lag}\")\n",
    "\n",
    "def second_order_diff_expr(col: str, lag: int = 1) -> pl.Expr:\n",
    "    # 二阶差分 = 一阶差分的差分\n",
    "    first_diff = pl.col(col) - pl.col(col).shift(lag)\n",
    "    second_diff = first_diff - first_diff.shift(lag)\n",
    "    return second_diff.alias(f\"{col}_second_order_diff_{lag}\")\n",
    "\n",
    "def momentum_ratio_expr(col: str, window: int = 200) -> pl.Expr:\n",
    "    # 动量比率 = x_t / x_{t-lag}\n",
    "    EPSILON = 1e-5\n",
    "    return ((pl.col(col).abs() + EPSILON).log1p() - (pl.col(col).abs() + EPSILON).shift(window).log1p()).alias(f\"{col}_momentum_ratio_{window}\")\n",
    "\n",
    "def rolling_volatility_expr(col: str, window: int) -> pl.Expr:\n",
    "    return pl.col(col).rolling_std(window).alias(f\"{col}_volatility_{window}\")\n",
    "\n",
    "def cross_minus_expr(a: str, b: str) -> pl.Expr:\n",
    "    return (pl.col(a) - (pl.col(b) + 1e-8)).alias(f\"{a}_minus_{b}\")\n",
    "\n",
    "def cols_to_transforms(\n",
    "        df: pl.DataFrame,\n",
    "        exclude_cols: List[str] = None\n",
    ") -> List[str]:\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = ['px', 'timestamp', 'timestamp_dt', 'symbol']\n",
    "\n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        cols = df.collect_schema().names()\n",
    "    else:\n",
    "        cols = df.columns\n",
    "\n",
    "    cols = [\n",
    "        col for col in cols\n",
    "        if col not in exclude_cols and not (\n",
    "                col.endswith('_rolling_mean') or\n",
    "                col.endswith('_rolling_std') or\n",
    "                col.endswith('_scaled')\n",
    "        ) and not col.startswith(\"z_\")\n",
    "    ]\n",
    "\n",
    "    return cols\n",
    "\n",
    "def batch_apply_single_exprs(\n",
    "        window: int,\n",
    "        lags: [int],\n",
    "        cols: List[str] = None\n",
    ") -> List[str]:\n",
    "    single_exprs = []\n",
    "    # single features transformation\n",
    "    for col in cols:\n",
    "        single_exprs.extend([\n",
    "            momentum_ratio_expr(col, window),\n",
    "            rolling_volatility_expr(col, window),\n",
    "        ])\n",
    "        for lag in lags:\n",
    "            single_exprs.extend([\n",
    "            lag_exprs(col, lag),\n",
    "            diff_expr(col, lag),\n",
    "            second_order_diff_expr(col, lag),\n",
    "        ])\n",
    "            \n",
    "    return single_exprs\n",
    "\n",
    "def batch_apply_multi_exprs(\n",
    "        cols: List[str] = None\n",
    ") -> List[str]:\n",
    "    multi_exprs = []\n",
    "\n",
    "    n = len(cols)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            a, b = cols[i], cols[j]\n",
    "            multi_exprs.extend([\n",
    "                cross_minus_expr(a, b),\n",
    "            ])\n",
    "\n",
    "    return multi_exprs\n",
    "\n",
    "def batch_apply_transforms(\n",
    "        df_to_transforms: pl.DataFrame,\n",
    "        window: int,\n",
    "        lags: [int],\n",
    "        log1p_cols: List[str] = None,\n",
    "        exclude_cols: List[str] = None,\n",
    ") -> pl.DataFrame:\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = ['px', 'timestamp', 'timestamp_dt', 'symbol']\n",
    "        \n",
    "    if log1p_cols is None:\n",
    "        log1p_cols = []\n",
    "\n",
    "    for col in log1p_cols:\n",
    "        if col in df_to_transforms.columns:\n",
    "            df_to_transforms = df_to_transforms.with_columns([\n",
    "                pl.col(col).clip(lower_bound=0.0).log1p().alias(col)\n",
    "            ])\n",
    "            \n",
    "    # base_cols = cols_to_transforms(df_to_transforms, exclude_cols)\n",
    "   \n",
    "    # single_exprs = batch_apply_single_exprs(window, lags, base_cols)\n",
    "    # multi_exprs = batch_apply_multi_exprs(base_cols)\n",
    "\n",
    "    # exprs = single_exprs + multi_exprs\n",
    "    # return df_to_transforms.with_columns(exprs)\n",
    "    return df_to_transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67429650-ff19-48a7-a11b-c752d155db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_df_by_month(\n",
    "    origin_input_df: pl.DataFrame,\n",
    "    ts_col: str = \"timestamp\"\n",
    ") -> List[pl.DataFrame]:\n",
    "    origin_input_df = origin_input_df.with_columns([\n",
    "        pl.col(ts_col).cast(pl.Datetime(\"ms\")).alias(f\"{ts_col}_dt\")  # 注意这里加了 \"ms\"\n",
    "    ])\n",
    "\n",
    "    origin_input_df = origin_input_df.with_columns([\n",
    "        pl.col(f\"{ts_col}_dt\").dt.truncate(\"1mo\").alias(\"month_start\")\n",
    "    ])\n",
    "\n",
    "    unique_months = origin_input_df.select(\"month_start\").unique().sort(\"month_start\")\n",
    "\n",
    "    monthly_dfs = [\n",
    "        origin_input_df.filter(pl.col(\"month_start\") == mt).drop(\"month_start\")\n",
    "        for mt in unique_months[\"month_start\"]\n",
    "    ]\n",
    "\n",
    "    return monthly_dfs\n",
    "\n",
    "    \n",
    "def split_df_by_week(\n",
    "    origin_input_df: pl.DataFrame,\n",
    "    ts_col: str = \"timestamp\"\n",
    ") -> List[pl.DataFrame]:\n",
    "    origin_input_df = origin_input_df.with_columns([\n",
    "        pl.col(ts_col).cast(pl.Datetime(\"ms\")).alias(f\"{ts_col}_dt\")  # 注意这里加了 \"ms\"\n",
    "    ])\n",
    "\n",
    "    origin_input_df = origin_input_df.with_columns([\n",
    "        pl.col(f\"{ts_col}_dt\").dt.truncate(\"1w\").alias(\"week_start\")\n",
    "    ])\n",
    "\n",
    "    unique_weeks = origin_input_df.select(\"week_start\").unique().sort(\"week_start\")\n",
    "\n",
    "    weekly_dfs = [\n",
    "        origin_input_df.filter(pl.col(\"week_start\") == wk).drop(\"week_start\")\n",
    "        for wk in unique_weeks[\"week_start\"]\n",
    "    ]\n",
    "\n",
    "    return weekly_dfs\n",
    "\n",
    "def clean_df_drop_nulls(\n",
    "        df_to_clean: pl.DataFrame,\n",
    "        null_threshold: int = 10000,\n",
    "        verbose: bool = True\n",
    ") -> pl.DataFrame:\n",
    "    pd_df = df_to_clean.to_pandas()\n",
    "\n",
    "    null_counts = pd_df.isnull().sum()\n",
    "    cols_to_drop = null_counts[null_counts > null_threshold].index\n",
    "\n",
    "    pd_df_cleaned = pd_df.drop(columns=cols_to_drop)\n",
    "    pd_df_clean = pd_df_cleaned.dropna()\n",
    "    pl_df_clean = pl.from_pandas(pd_df_clean)\n",
    "\n",
    "    if verbose:\n",
    "        max_null_col = null_counts.idxmax()\n",
    "        max_null_count = null_counts.max()\n",
    "        print(\"各列空值数量：\")\n",
    "        print(null_counts[null_counts > 0])\n",
    "        print(f\"删除空值超过 {null_threshold} 的列：{list(cols_to_drop)}\")\n",
    "        print(f\"删除列后，DataFrame形状：{pd_df_cleaned.shape}\")\n",
    "        print(f\"空值最多的列是：{max_null_col}，共有 {max_null_count} 个空值\")\n",
    "        print(f\"删除空值行后，DataFrame形状：{pd_df_clean.shape}\")\n",
    "\n",
    "    return pl_df_clean\n",
    "\n",
    "def avg_steps_to_volatility(prices: np.ndarray, target_ratio: float) -> int:\n",
    "    n = len(prices)\n",
    "    steps_list = []\n",
    "    for i in tqdm(range(n), desc=f\"cal abs change {target_ratio*100:.2f}% avg steps\"):\n",
    "        start_price = prices[i]\n",
    "        steps = -1\n",
    "        for j in range(i + 1, n):\n",
    "            change = abs(prices[j] / start_price - 1)\n",
    "            if change >= target_ratio:\n",
    "                steps = j - i\n",
    "                break\n",
    "        if steps != -1:\n",
    "            steps_list.append(steps)\n",
    "    if len(steps_list) == 0:\n",
    "        return -1\n",
    "    return int(np.mean(steps_list))\n",
    "\n",
    "def future_return_expr(price_col: str, step: int) -> pl.Expr:\n",
    "    return ((pl.col(price_col).shift(-step) - pl.col(price_col)) / pl.col(price_col)).alias(f\"future_return_{step}\")\n",
    "\n",
    "def rolling_minmax_scaled_expr(\n",
    "        col: str,\n",
    "        min_col: str,\n",
    "        max_col: str,\n",
    "        scaled_col: str\n",
    ") -> pl.Expr:\n",
    "    return (\n",
    "        ((pl.col(col) - pl.col(min_col)) / (pl.col(max_col) - pl.col(min_col) + 1e-9))\n",
    "        .clip(0.0, 1.0)\n",
    "        .fill_null(0.5)\n",
    "        .alias(scaled_col)\n",
    "    )\n",
    "\n",
    "def rolling_minmax_normalize(rollin_df: pl.DataFrame, window: int) -> pl.DataFrame:\n",
    "    columns_to_normalize = [\n",
    "        col for col in rollin_df.columns\n",
    "        if col not in ['px', 'timestamp', 'timestamp_dt', 'symbol']\n",
    "           and not col.startswith(\"future_return_\")\n",
    "           and not col.endswith('_scaled')  # scaled 是最终产物，保留\n",
    "           and not (\n",
    "                col.endswith('_rolling_mean') or\n",
    "                col.endswith('_rolling_std') or\n",
    "                col.endswith('_rolling_max') or\n",
    "                col.endswith('_rolling_min')\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    rolling_cols = []\n",
    "    for column in columns_to_normalize:\n",
    "        rolling_cols.extend([\n",
    "            pl.col(column).rolling_max(window, min_samples=1).alias(f\"{column}_rolling_max\"),\n",
    "            pl.col(column).rolling_min(window, min_samples=1).alias(f\"{column}_rolling_min\"),\n",
    "        ])\n",
    "\n",
    "    intermediate_cols = [\n",
    "                            f\"{column}_rolling_max\" for column in columns_to_normalize\n",
    "                        ] + [\n",
    "                            f\"{column}_rolling_min\" for column in columns_to_normalize\n",
    "                        ]\n",
    "\n",
    "    return (\n",
    "        rollin_df\n",
    "        .with_columns(rolling_cols)\n",
    "        .with_columns([\n",
    "            rolling_minmax_scaled_expr(\n",
    "                col=column,\n",
    "                min_col=f\"{column}_rolling_min\",\n",
    "                max_col=f\"{column}_rolling_max\",\n",
    "                scaled_col=f\"{column}_scaled\"\n",
    "            ) for column in columns_to_normalize\n",
    "        ])\n",
    "        .drop(intermediate_cols)\n",
    "    )\n",
    "\n",
    "def rolling_mean_tanh_scaled_expr(\n",
    "        col: str,\n",
    "        scaled_col: str,\n",
    "        window: int\n",
    ") -> pl.Expr:\n",
    "    return (\n",
    "        pl.col(col)\n",
    "        # .rolling_mean(window, min_samples=1)\n",
    "        .tanh()\n",
    "        # .rolling_mean(window, min_samples=1)\n",
    "        .alias(scaled_col)\n",
    "    )\n",
    "\n",
    "def rolling_mean_tanh_normalize(rollin_df: pl.DataFrame, window: int) -> pl.DataFrame:\n",
    "    columns_to_normalize = [\n",
    "        col for col in rollin_df.columns\n",
    "        if col not in ['px', 'timestamp', 'timestamp_dt', 'symbol']\n",
    "           and not col.startswith(\"future_return_\")\n",
    "           and not col.endswith('_scaled')\n",
    "    ]\n",
    "\n",
    "    return rollin_df.with_columns([\n",
    "        rolling_mean_tanh_scaled_expr(\n",
    "            col=column,\n",
    "            scaled_col=f\"{column}_scaled\",\n",
    "            window=window\n",
    "        ) for column in columns_to_normalize\n",
    "    ])\n",
    "\n",
    "def rolling_z_tanh_normalize(\n",
    "    rollin_df: pl.DataFrame,\n",
    "    window: int,\n",
    "    rolling_mean_window: int,\n",
    ") -> pl.DataFrame:\n",
    "    columns_to_normalize = [\n",
    "        col for col in rollin_df.columns\n",
    "        if col not in ['px', 'timestamp', 'timestamp_dt', 'symbol']\n",
    "           and not col.startswith(\"future_return_\")\n",
    "           and not col.endswith('_scaled')\n",
    "    ]\n",
    "\n",
    "    return rollin_df.with_columns([\n",
    "        z_score_tanh_expr(\n",
    "            col=column,\n",
    "            scaled_col=f\"{column}_zscaled\",\n",
    "            window=window,\n",
    "            rolling_mean_window=rolling_mean_window,\n",
    "        ) for column in columns_to_normalize\n",
    "    ]) \n",
    "\n",
    "def z_score_tanh_expr(\n",
    "    col: str,\n",
    "    scaled_col: str,\n",
    "    window: int,\n",
    "    rolling_mean_window: int,\n",
    ") -> pl.Expr:\n",
    "    EPSILON = 1e-6\n",
    "    mean_expr = pl.col(col).rolling_mean(window, min_samples=1)\n",
    "    std_expr = pl.col(col).rolling_std(window, min_samples=1).fill_nan(0)\n",
    "\n",
    "    return (\n",
    "        ((pl.col(col) - mean_expr) / (std_expr + EPSILON))\n",
    "        .fill_nan(0)\n",
    "        .fill_null(0)\n",
    "        .clip(-3.0, 3.0)\n",
    "        .tanh()\n",
    "        .rolling_mean(rolling_mean_window, min_samples=1)\n",
    "        .alias(scaled_col)\n",
    "    )\n",
    "\n",
    "\n",
    "def rolling_mean_smooth(rollin_df: pl.DataFrame, window: int) -> pl.DataFrame:\n",
    "    columns_to_smooth = [\n",
    "        col for col in rollin_df.columns\n",
    "        if col not in ['px', 'timestamp', 'timestamp_dt', 'symbol']\n",
    "           and not col.startswith(\"future_return_\")\n",
    "           and not col.endswith('_scaled')\n",
    "    ]\n",
    "\n",
    "    return rollin_df.with_columns([\n",
    "        rolling_mean_scaled_expr(\n",
    "            col=column,\n",
    "            scaled_col=f\"{column}_scaled\",\n",
    "            window=window\n",
    "        ) for column in columns_to_smooth\n",
    "    ])\n",
    "\n",
    "def rolling_mean_scaled_expr(\n",
    "        col: str,\n",
    "        scaled_col: str,\n",
    "        window: int\n",
    ") -> pl.Expr:\n",
    "    return (\n",
    "        pl.col(col)\n",
    "        .rolling_mean(window)\n",
    "        .fill_null(strategy=\"zero\")  # 或 strategy=\"forward\" 也行\n",
    "        .alias(scaled_col)\n",
    "    )\n",
    "\n",
    "\n",
    "def rolling_ic_ir_icto_index(\n",
    "        df: pl.DataFrame,\n",
    "        target_col: str,\n",
    "        exclude_prefixes: list[str],\n",
    "        window_size: int,\n",
    "        step: int = 1,\n",
    ") -> pl.DataFrame:\n",
    "    feature_cols = [\n",
    "        col for col in df.columns\n",
    "        if col.endswith(\"_scaled\") \n",
    "            and (col.startswith(\"z_\") or col.startswith(\"raw_\")) \n",
    "            and all(not col.startswith(prefix) for prefix in exclude_prefixes)\n",
    "            and not col.startswith(\"future_return_\")\n",
    "            and col != \"px\"\n",
    "    ]\n",
    "\n",
    "    # feature_cols = [\n",
    "    #     col for col in df.columns\n",
    "    #     if col.startswith(\"z_\") \n",
    "    #         and all(not col.startswith(prefix) for prefix in exclude_prefixes)\n",
    "    #         and not col.startswith(\"future_return_\")\n",
    "    #         and col != \"px\"\n",
    "    # ]\n",
    "\n",
    "    n = df.height\n",
    "    results = []\n",
    "    prev_ranks = {}\n",
    "\n",
    "    for start in tqdm(range(0, n - window_size + 1, step), desc=\"Rolling IC & ICTO\"):\n",
    "        end = start + window_size\n",
    "        df_win = df.slice(start, window_size)\n",
    "\n",
    "        # rank 转换\n",
    "        df_ranked = df_win.with_columns([\n",
    "            (pl.col(c).rank(method=\"average\") / window_size).alias(c + \"_rank\") for c in feature_cols + [target_col]\n",
    "        ])\n",
    "        target_rank_col = target_col + \"_rank\"\n",
    "\n",
    "        for feat in feature_cols:\n",
    "            feat_rank_col = feat + \"_rank\"\n",
    "            ic = df_ranked.select(\n",
    "                pl.corr(pl.col(feat_rank_col), pl.col(target_rank_col)).alias(\"ic\")\n",
    "            ).to_series()[0]\n",
    "\n",
    "            turnover = None\n",
    "            if feat in prev_ranks:\n",
    "                cur_ranks = df_ranked[feat_rank_col].to_numpy()\n",
    "                prev = prev_ranks[feat]\n",
    "                if len(prev) == len(cur_ranks):\n",
    "                    turnover = np.mean(np.abs(cur_ranks - prev))\n",
    "\n",
    "            # 更新 prev_ranks\n",
    "            prev_ranks[feat] = df_ranked[feat_rank_col].to_numpy()\n",
    "\n",
    "            results.append({\n",
    "                \"window_start\": int(start),\n",
    "                \"window_end\": int(end - 1),\n",
    "                \"factor\": str(feat),\n",
    "                \"ic\": float(ic) if not np.isnan(ic) else None,\n",
    "                \"turnover\": float(turnover) if turnover is not None else None\n",
    "            })\n",
    "\n",
    "    df_result = pl.DataFrame(\n",
    "        results,\n",
    "        schema={\n",
    "            \"window_start\": pl.Int64,\n",
    "            \"window_end\": pl.Int64,\n",
    "            \"factor\": pl.Utf8,\n",
    "            \"ic\": pl.Float64,\n",
    "            \"turnover\": pl.Float64,\n",
    "        }\n",
    "    )      \n",
    "    return (\n",
    "        df_result\n",
    "        .group_by(\"factor\")\n",
    "        .agg([\n",
    "            pl.mean(\"ic\").alias(\"mean_ic\"),\n",
    "            pl.std(\"ic\").alias(\"std_ic\"),\n",
    "            pl.mean(\"turnover\").alias(\"mean_turnover\")\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col(\"mean_ic\") / pl.col(\"std_ic\")).alias(\"ir\"),\n",
    "            (pl.col(\"mean_ic\") / (pl.col(\"mean_turnover\") + 1e-8)).abs().alias(\"icto\")\n",
    "        ])\n",
    "        .sort(\"icto\", descending=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c30d194-5897-4d42-a831-d70640c473aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "def fast_build_long_cross_sections(symbol_dfs: dict[str, pl.DataFrame]) -> pl.DataFrame:\n",
    "    long_df = pl.concat(list(symbol_dfs.values()))\n",
    "\n",
    "    return long_df.sort(\"timestamp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bb5b20-9803-4ea0-a432-2d154dbd4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_symbol(\n",
    "    symbol: str,\n",
    "    threshold: str = \"0.002\",\n",
    "    feat_cal_window: str = \"2000\",\n",
    "    data_dir: str = \"C:/quant/data/binance_resampled_data/\",\n",
    "    feat_trans_window: int = 350,\n",
    "    feat_trans_lags: list[int] = [5, 10, 20, 50, 100, 150, 200],\n",
    "    feat_norm_window: int = 500,\n",
    "    feat_norm_rolling_mean_window: int = 10,\n",
    ") -> pl.DataFrame:\n",
    "    symbol.upper()\n",
    "    \n",
    "    file = f\"{symbol}_factors_threshold{threshold}_rolling{feat_cal_window}.csv\"\n",
    "    path = data_dir + file\n",
    "    df = pl.read_csv(path)\n",
    "\n",
    "    # 删掉不需要的列\n",
    "    df = df.drop([\n",
    "        \"top_acc_longShortRatio\", \"top_pos_longShortRatio\", \"acc_longShortRatio\"\n",
    "    ])\n",
    "\n",
    "    # 对部分列进行 log1p + lag 变换\n",
    "    cols_to_log1p = [\n",
    "        \"far_bid_price\", \"far_ask_price\",\n",
    "        \"best_bid_price\", \"best_ask_price\",\n",
    "        \"sum_buy_sz\", \"sum_sell_sz\",\n",
    "        \"ts_duration\", \"real_bid_amount_sum\", \"real_ask_amount_sum\",\n",
    "    ]\n",
    "    df = batch_apply_transforms(df, feat_trans_window, feat_trans_lags, cols_to_log1p)\n",
    "\n",
    "    # rolling z-score + tanh 归一\n",
    "    df = rolling_z_tanh_normalize(df, feat_norm_window, feat_norm_rolling_mean_window)\n",
    "\n",
    "    # 去掉 std=0 的列\n",
    "    stds = df.select([\n",
    "        pl.col(col).std().alias(col)\n",
    "        for col in df.columns\n",
    "        if df[col].dtype in (pl.Float64, pl.Int64)\n",
    "    ])\n",
    "    zero_std_cols = [col for col in stds.columns if stds[0, col] == 0.0]\n",
    "    df = df.drop(zero_std_cols)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2a88b8-2140-46ef-8ec9-e4b4ea0e10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_valid_cross_sections(long_df: pl.DataFrame, num_symbols: int) -> pl.DataFrame:\n",
    "    valid_ts = (\n",
    "        long_df\n",
    "        .filter(pl.col(\"px\").is_not_null())\n",
    "        .group_by(\"timestamp\")\n",
    "        .agg(pl.len().alias(\"len\"))\n",
    "        .filter(pl.col(\"len\") == num_symbols)\n",
    "        .select(\"timestamp\")\n",
    "    )\n",
    "    return long_df.join(valid_ts, on=\"timestamp\", how=\"inner\")\n",
    "\n",
    "\n",
    "def build_long_cross_sections_fast(symbol_dfs: dict[str, pl.DataFrame]) -> pl.DataFrame:\n",
    "    # 1. 获取所有币种的所有时间戳，合并去重，得到全局时间轴 timeline\n",
    "    all_timestamps = (\n",
    "        pl.concat(\n",
    "            [df.select(\"timestamp\").unique() for df in symbol_dfs.values()]\n",
    "        )\n",
    "        .unique()\n",
    "        .sort(\"timestamp\")\n",
    "    )\n",
    "\n",
    "    result_dfs = []\n",
    "\n",
    "    for symbol, df in symbol_dfs.items():\n",
    "        # 确保 df 按时间戳排序\n",
    "        df_sorted = df.sort(\"timestamp\")\n",
    "        # 2. 用 timeline 左连接（asof join）当前币种数据，找最近小于等于时间戳的行\n",
    "        joined = all_timestamps.join_asof(\n",
    "            df_sorted,\n",
    "            on=\"timestamp\",\n",
    "            strategy=\"backward\"  # 小于等于左表时间戳的最近一条右表数据\n",
    "        )\n",
    "        # 3. 补充 symbol 列（如果df本身有，确认无误）\n",
    "        # 如果原始 df 有 symbol，这里确认 symbol 是正确的\n",
    "        joined = joined.with_columns(pl.lit(symbol).alias(\"symbol\"))\n",
    "        result_dfs.append(joined)\n",
    "\n",
    "    long_df = pl.concat(result_dfs).sort([\"timestamp\", \"symbol\"])\n",
    "    clean_df = filter_valid_cross_sections(long_df, len(symbol_dfs))\n",
    "\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef06c1c-67e0-4fc0-8ba5-4e3c824ba0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(36508, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(34508, 7021)\n",
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(31824, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(29824, 7021)\n",
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(33639, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(31639, 7021)\n",
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(49282, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(47282, 7021)\n",
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(31198, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(29198, 7021)\n",
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(44730, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(42730, 7021)\n",
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(36716, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(34716, 7021)\n",
      "各列空值数量：\n",
      "sum_buy_sz_momentum_ratio_2000                              2000\n",
      "sum_buy_sz_volatility_2000                                  1999\n",
      "sum_buy_sz_lag_5                                               5\n",
      "sum_buy_sz_diff_5                                              5\n",
      "sum_buy_sz_second_order_diff_5                                10\n",
      "                                                            ... \n",
      "factor_oi_momentum_long_term_punch_diff_150                  150\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_150     300\n",
      "factor_oi_momentum_long_term_punch_lag_200                   200\n",
      "factor_oi_momentum_long_term_punch_diff_200                  200\n",
      "factor_oi_momentum_long_term_punch_second_order_diff_200     400\n",
      "Length: 1449, dtype: int64\n",
      "删除空值超过 10000 的列：[]\n",
      "删除列后，DataFrame形状：(35054, 7021)\n",
      "空值最多的列是：sum_buy_sz_momentum_ratio_2000，共有 2000 个空值\n",
      "删除空值行后，DataFrame形状：(33054, 7021)\n",
      "共 15 周\n",
      "第 1 周:\n",
      "  btcusdt: (6690, 7022)\n",
      "  bnbusdt: (4126, 7022)\n",
      "  ethusdt: (3816, 7022)\n",
      "  dogeusdt: (4283, 7022)\n",
      "  ltcusdt: (2830, 7022)\n",
      "  avaxusdt: (4331, 7022)\n",
      "  solusdt: (4708, 7022)\n",
      "  xrpusdt: (5891, 7022)\n",
      "第 2 周:\n",
      "  btcusdt: (2063, 7022)\n",
      "  bnbusdt: (1209, 7022)\n",
      "  ethusdt: (1625, 7022)\n",
      "  dogeusdt: (1989, 7022)\n",
      "  ltcusdt: (1608, 7022)\n",
      "  avaxusdt: (2230, 7022)\n",
      "  solusdt: (2799, 7022)\n",
      "  xrpusdt: (1548, 7022)\n",
      "第 3 周:\n",
      "  btcusdt: (2769, 7022)\n",
      "  bnbusdt: (1908, 7022)\n",
      "  ethusdt: (2214, 7022)\n",
      "  dogeusdt: (2992, 7022)\n",
      "  ltcusdt: (1824, 7022)\n",
      "  avaxusdt: (3117, 7022)\n",
      "  solusdt: (2257, 7022)\n",
      "  xrpusdt: (1954, 7022)\n",
      "第 4 周:\n",
      "  btcusdt: (1578, 7022)\n",
      "  bnbusdt: (1019, 7022)\n",
      "  ethusdt: (1206, 7022)\n",
      "  dogeusdt: (1745, 7022)\n",
      "  ltcusdt: (1471, 7022)\n",
      "  avaxusdt: (2139, 7022)\n",
      "  solusdt: (1439, 7022)\n",
      "  xrpusdt: (1224, 7022)\n",
      "第 5 周:\n",
      "  btcusdt: (2170, 7022)\n",
      "  bnbusdt: (2748, 7022)\n",
      "  ethusdt: (3386, 7022)\n",
      "  dogeusdt: (4560, 7022)\n",
      "  ltcusdt: (3274, 7022)\n",
      "  avaxusdt: (3338, 7022)\n",
      "  solusdt: (2379, 7022)\n",
      "  xrpusdt: (2162, 7022)\n",
      "第 6 周:\n",
      "  btcusdt: (2106, 7022)\n",
      "  bnbusdt: (3719, 7022)\n",
      "  ethusdt: (3200, 7022)\n",
      "  dogeusdt: (5952, 7022)\n",
      "  ltcusdt: (3252, 7022)\n",
      "  avaxusdt: (4340, 7022)\n",
      "  solusdt: (3147, 7022)\n",
      "  xrpusdt: (3510, 7022)\n",
      "第 7 周:\n",
      "  btcusdt: (3251, 7022)\n",
      "  bnbusdt: (2540, 7022)\n",
      "  ethusdt: (2726, 7022)\n",
      "  dogeusdt: (3822, 7022)\n",
      "  ltcusdt: (2317, 7022)\n",
      "  avaxusdt: (3688, 7022)\n",
      "  solusdt: (2779, 7022)\n",
      "  xrpusdt: (1631, 7022)\n",
      "第 8 周:\n",
      "  btcusdt: (2007, 7022)\n",
      "  bnbusdt: (1994, 7022)\n",
      "  ethusdt: (1701, 7022)\n",
      "  dogeusdt: (2735, 7022)\n",
      "  ltcusdt: (1764, 7022)\n",
      "  avaxusdt: (2849, 7022)\n",
      "  solusdt: (1802, 7022)\n",
      "  xrpusdt: (1363, 7022)\n",
      "第 9 周:\n",
      "  btcusdt: (1434, 7022)\n",
      "  bnbusdt: (1436, 7022)\n",
      "  ethusdt: (1313, 7022)\n",
      "  dogeusdt: (2186, 7022)\n",
      "  ltcusdt: (1117, 7022)\n",
      "  avaxusdt: (2215, 7022)\n",
      "  solusdt: (1646, 7022)\n",
      "  xrpusdt: (1120, 7022)\n",
      "第 10 周:\n",
      "  btcusdt: (1866, 7022)\n",
      "  bnbusdt: (1484, 7022)\n",
      "  ethusdt: (1991, 7022)\n",
      "  dogeusdt: (2623, 7022)\n",
      "  ltcusdt: (1522, 7022)\n",
      "  avaxusdt: (2817, 7022)\n",
      "  solusdt: (2321, 7022)\n",
      "  xrpusdt: (1233, 7022)\n",
      "第 11 周:\n",
      "  btcusdt: (2387, 7022)\n",
      "  bnbusdt: (1598, 7022)\n",
      "  ethusdt: (2423, 7022)\n",
      "  dogeusdt: (2617, 7022)\n",
      "  ltcusdt: (1724, 7022)\n",
      "  avaxusdt: (2893, 7022)\n",
      "  solusdt: (2614, 7022)\n",
      "  xrpusdt: (1794, 7022)\n",
      "第 12 周:\n",
      "  btcusdt: (1614, 7022)\n",
      "  bnbusdt: (1058, 7022)\n",
      "  ethusdt: (1604, 7022)\n",
      "  dogeusdt: (1874, 7022)\n",
      "  ltcusdt: (1035, 7022)\n",
      "  avaxusdt: (2035, 7022)\n",
      "  solusdt: (1988, 7022)\n",
      "  xrpusdt: (1356, 7022)\n",
      "第 13 周:\n",
      "  btcusdt: (1014, 7022)\n",
      "  bnbusdt: (544, 7022)\n",
      "  ethusdt: (978, 7022)\n",
      "  dogeusdt: (1418, 7022)\n",
      "  ltcusdt: (983, 7022)\n",
      "  avaxusdt: (1436, 7022)\n",
      "  solusdt: (1415, 7022)\n",
      "  xrpusdt: (1027, 7022)\n",
      "第 14 周:\n",
      "  btcusdt: (1457, 7022)\n",
      "  bnbusdt: (1115, 7022)\n",
      "  ethusdt: (1385, 7022)\n",
      "  dogeusdt: (3109, 7022)\n",
      "  ltcusdt: (1382, 7022)\n",
      "  avaxusdt: (2172, 7022)\n",
      "  solusdt: (1463, 7022)\n",
      "  xrpusdt: (2994, 7022)\n",
      "第 15 周:\n",
      "  btcusdt: (2102, 7022)\n",
      "  bnbusdt: (3326, 7022)\n",
      "  ethusdt: (2071, 7022)\n",
      "  dogeusdt: (5377, 7022)\n",
      "  ltcusdt: (3095, 7022)\n",
      "  avaxusdt: (3130, 7022)\n",
      "  solusdt: (1959, 7022)\n",
      "  xrpusdt: (4247, 7022)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def process_all_symbols(params_dict):\n",
    "    symbol_dfs = {}\n",
    "    for sym, param in params_dict.items():\n",
    "        df = process_single_symbol(\n",
    "            symbol=sym,\n",
    "            threshold=param.get(\"threshold\", \"0.002\"),\n",
    "            feat_trans_window=param.get(\"feat_trans_window\", 350),\n",
    "            feat_norm_window=param.get(\"feat_norm_window\", 500),\n",
    "            feat_norm_rolling_mean_window=param.get(\"feat_norm_rolling_mean_window\", 10),\n",
    "        )\n",
    "        df = df.with_columns(pl.lit(sym).alias(\"symbol\"))\n",
    "        symbol_dfs[sym] = df\n",
    "        \n",
    "    return symbol_dfs\n",
    "\n",
    "# weekly_dataframes = split_df_by_week(a_df_filtered)\n",
    "# print(\"num weekly dfs:\", len(weekly_dataframes))\n",
    "\n",
    "feat_trans_window = 2000\n",
    "feat_norm_window = 2000\n",
    "feat_norm_rolling_mean_window = 200\n",
    "\n",
    "symbol_params = {\n",
    "    \"btcusdt\": {\n",
    "        \"threshold\": \"0.001\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    \"bnbusdt\": {\n",
    "        \"threshold\": \"0.001\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    \"ethusdt\": {\n",
    "        \"threshold\": \"0.002\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    \"dogeusdt\": {\n",
    "        \"threshold\": \"0.002\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    # \"tonusdt\": {\n",
    "    #     \"threshold\": \"0.002\",\n",
    "    #     \"feat_trans_window\": feat_trans_window,\n",
    "    #     \"feat_norm_window\": feat_norm_window,\n",
    "    #     \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    # },\n",
    "    # \"filusdt\": {\n",
    "    #     \"threshold\": \"0.002\",\n",
    "    #     \"feat_trans_window\": feat_trans_window,\n",
    "    #     \"feat_norm_window\": feat_norm_window,\n",
    "    #     \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    # },\n",
    "    \"ltcusdt\": {\n",
    "        \"threshold\": \"0.002\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    \"avaxusdt\": {\n",
    "        \"threshold\": \"0.002\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    # \"atomusdt\": {\n",
    "    #     \"threshold\": \"0.002\",\n",
    "    #     \"feat_trans_window\": feat_trans_window,\n",
    "    #     \"feat_norm_window\": feat_norm_window,\n",
    "    #     \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    # },\n",
    "    \"solusdt\": {\n",
    "        \"threshold\": \"0.002\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    \"xrpusdt\": {\n",
    "        \"threshold\": \"0.002\",\n",
    "        \"feat_trans_window\": feat_trans_window,\n",
    "        \"feat_norm_window\": feat_norm_window,\n",
    "        \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    },\n",
    "    # \"uniusdt\": {\n",
    "    #     \"threshold\": \"0.002\",\n",
    "    #     \"feat_trans_window\": feat_trans_window,\n",
    "    #     \"feat_norm_window\": feat_norm_window,\n",
    "    #     \"feat_norm_rolling_mean_window\": feat_norm_rolling_mean_window,\n",
    "    # },\n",
    "}\n",
    "\n",
    "symbol_dfs = process_all_symbols(symbol_params)\n",
    "\n",
    "symbol_weekly = {}\n",
    "max_weeks = 0\n",
    "\n",
    "# 拆分每个币种的周数据（list），记录最长周数\n",
    "for sym, df in symbol_dfs.items():\n",
    "    df = clean_df_drop_nulls(df)\n",
    "    dfs = split_df_by_week(df)  # 只拿 list\n",
    "    symbol_weekly[sym] = dfs\n",
    "    if len(dfs) > max_weeks:\n",
    "        max_weeks = len(dfs)\n",
    "\n",
    "result = []\n",
    "\n",
    "# 遍历所有周（用索引表示周数）\n",
    "for wk_idx in range(max_weeks):\n",
    "    week_dict = {}\n",
    "    for sym, dfs in symbol_weekly.items():\n",
    "        if wk_idx < len(dfs):\n",
    "            week_dict[sym] = dfs[wk_idx]\n",
    "    result.append(week_dict)\n",
    "\n",
    "print(f\"共 {len(result)} 周\")\n",
    "for i, week_dict in enumerate(result):\n",
    "    print(f\"第 {i+1} 周:\")\n",
    "    for sym, df in week_dict.items():\n",
    "        print(f\"  {sym}: {df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8668cea-4fe9-49e6-b920-9454b875cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624c718-9cef-4bfe-8c54-1a987da6c23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "weekly_long_dfs = []\n",
    "\n",
    "for week_symbol_dfs in tqdm(result):\n",
    "    long_df = build_long_cross_sections_fast(week_symbol_dfs)  # 就是你写的函数\n",
    "    weekly_long_dfs.append(long_df)\n",
    "\n",
    "print(len(weekly_long_dfs))\n",
    "print(weekly_long_dfs[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a9d7c-d433-4337-adec-7afa0c6586c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每周长度列表\n",
    "weekly_lengths = [len(df) for df in weekly_long_dfs]\n",
    "\n",
    "# 总长度\n",
    "total_len = sum(weekly_lengths)\n",
    "\n",
    "# 平均每周长度\n",
    "avg_len = total_len / len(weekly_lengths)\n",
    "\n",
    "# 打印信息\n",
    "print(f\"总共 {len(weekly_long_dfs)} 周\")\n",
    "print(f\"总行数: {total_len}\")\n",
    "print(f\"平均每周行数: {avg_len:.2f}\")\n",
    "\n",
    "# 也可以查看最近几周的 df 结构\n",
    "print(weekly_long_dfs[-3].head())\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(weekly_lengths, marker='o')\n",
    "plt.title(\"crosec len\")\n",
    "plt.xlabel(\"week\")\n",
    "plt.ylabel(\"len\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b965055-74c5-470b-8ec8-427e294bd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_dataframes = []\n",
    "\n",
    "le_symbol = LabelEncoder()\n",
    "all_symbols = set()\n",
    "\n",
    "N = 2000\n",
    "\n",
    "\n",
    "# 第一步：提取所有symbol，用于统一label encoding\n",
    "for df in tqdm(weekly_long_dfs):\n",
    "    all_symbols.update(df[\"symbol\"].unique())\n",
    "\n",
    "# 拿全局symbol顺序做LabelEncoder，确保 embedding 一致性\n",
    "le_symbol.fit(sorted(list(all_symbols)))\n",
    "\n",
    "for long_df in weekly_long_dfs:\n",
    "    # 给 symbol 编码\n",
    "    symbol_encoded = le_symbol.transform(long_df['symbol'].to_list())\n",
    "    long_df = long_df.with_columns([pl.Series('enc_cat_symbol', symbol_encoded)])\n",
    "    \n",
    "    # 加 row_nr\n",
    "    long_temp_df = long_df.with_row_index(name=\"row_nr\")\n",
    "    \n",
    "    # 计算未来收益率\n",
    "    df_with_future = (\n",
    "        long_temp_df.sort([\"symbol\", \"timestamp\"])\n",
    "        .group_by(\"symbol\")\n",
    "        .map_groups(lambda group: group.with_columns([\n",
    "            group[\"px\"].shift(-N).alias(\"px_future\"),\n",
    "            (group[\"px\"].shift(-N) / group[\"px\"]).log().alias(f\"future_return_{N}\")\n",
    "        ]))\n",
    "        .sort(\"row_nr\")\n",
    "        .drop(\"row_nr\")\n",
    "    )\n",
    "    \n",
    "    weekly_dataframes.append(df_with_future)\n",
    "\n",
    "print(weekly_dataframes[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f05334-0391-4732-88f5-4746cdd74644",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_prefixes = ['px', 'timestamp', 'timestamp_dt', 'symbol']\n",
    "target_col = f\"future_return_{N}\"\n",
    "\n",
    "# 用第一个 df 定义 feature_cols\n",
    "sample_df = weekly_dataframes[0]\n",
    "feature_cols = [\n",
    "    col for col in sample_df.columns\n",
    "    if (col.endswith(\"_zscaled\") or col == \"enc_cat_symbol\")\n",
    "    and all(not col.startswith(prefix) for prefix in exclude_prefixes)\n",
    "    and not col.startswith(\"future_return_\")\n",
    "    and col != \"px\"\n",
    "]\n",
    "\n",
    "cat_idxs = [feature_cols.index('enc_cat_symbol')]\n",
    "cat_dims = [sample_df.select('enc_cat_symbol').n_unique()]\n",
    "cat_emb_dim = 4\n",
    "print(len(feature_cols), cat_idxs, cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b316a-d96c-4b26-a919-f52ece1f0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cross_section(symbols, y_true, y_binary, y_pred_prob, px, alpha=1.0):\n",
    "    x = np.arange(len(symbols))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    width = 0.2\n",
    "\n",
    "    # 真实未来收益（连续）\n",
    "    ax1.bar(x - width, y_true, width=width, label='Future Return', alpha=0.6)\n",
    "    ax1.set_ylabel('Future Return')\n",
    "\n",
    "    # 价格线\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x, px, label='Price', color='tab:blue', marker='o')\n",
    "    ax2.set_ylabel('Price')\n",
    "\n",
    "    # 分类标签（二分类）\n",
    "    ax3 = ax1.twinx()\n",
    "    ax3.spines.right.set_position((\"outward\", 60))\n",
    "    ax3.scatter(x, y_binary, label='GMM Label', color='tab:orange', marker='x')\n",
    "    ax3.set_ylim(-0.1, 1.1)\n",
    "    ax3.set_ylabel('Binary Label')\n",
    "\n",
    "    # 预测概率\n",
    "    ax4 = ax1.twinx()\n",
    "    ax4.spines.right.set_position((\"outward\", 120))\n",
    "    ax4.plot(x, y_pred_prob, label='Predicted Prob', color='tab:green', marker='^')\n",
    "    ax4.set_ylim(-0.05, 1.05)\n",
    "    ax4.set_ylabel('Predicted Probability')\n",
    "\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(symbols, rotation=45)\n",
    "    ax1.set_xlabel('Symbols')\n",
    "\n",
    "    # 合并图例\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    lines_3, labels_3 = ax3.get_legend_handles_labels()\n",
    "    lines_4, labels_4 = ax4.get_legend_handles_labels()\n",
    "\n",
    "    ax1.legend(\n",
    "        lines_1 + lines_2 + lines_3 + lines_4,\n",
    "        labels_1 + labels_2 + labels_3 + labels_4,\n",
    "        loc='upper left'\n",
    "    )\n",
    "\n",
    "    plt.title(\"Cross-Section Comparison at One Timestamp\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe8623-9034-4078-9ae8-92758b1cbd79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_train_weeks = 2 # 可配置\n",
    "n_val_weeks = 1    # 一般 1 周验证\n",
    "n_test_weeks = 1   # 后 1 周做 test\n",
    "\n",
    "tabnet = None\n",
    "\n",
    "all_preds = []  # 放到 for 循环外\n",
    "\n",
    "for i in range(len(weekly_dataframes) - n_train_weeks - n_val_weeks - n_test_weeks + 1):\n",
    "    train_dfs = weekly_dataframes[i : i + n_train_weeks]\n",
    "    val_dfs = weekly_dataframes[i + n_train_weeks : i + n_train_weeks + n_val_weeks]\n",
    "    test_dfs = weekly_dataframes[i + n_train_weeks + n_val_weeks : i + n_train_weeks + n_val_weeks + n_test_weeks]\n",
    "\n",
    "    train_df = pl.concat(train_dfs)\n",
    "    val_df = pl.concat(val_dfs)\n",
    "    test_df = pl.concat(test_dfs)\n",
    "    \n",
    "    def process_df_np(df):\n",
    "        df = df.sort('timestamp').drop_nulls(subset=feature_cols + [target_col, 'px'])\n",
    "        X = df.select(feature_cols).to_numpy()  # Polars DataFrame 转 numpy ndarray\n",
    "        y = df.select(target_col).to_numpy().reshape(-1, 1)\n",
    "        px = df.select('px').to_numpy()\n",
    "        ts = df.select('timestamp').to_numpy()\n",
    "        symbol_enc = df.select(\"enc_cat_symbol\")\n",
    "        return X, y, px, ts, symbol_enc\n",
    "\n",
    "    X_train, y_train, px_train, ts_train, sb_train = process_df_np(train_df)\n",
    "    X_val, y_val, px_val, ts_val, sb_val = process_df_np(val_df)\n",
    "    X_test, y_test, px_test, ts_test, sb_test = process_df_np(test_df)\n",
    "\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Fold {i}: Train {i}~{i+n_train_weeks-1}, Val {i+n_train_weeks}, Test {i+n_train_weeks+1}\")\n",
    "    print(\"Train:\", train_df['timestamp_dt'][0], \"to\", train_df['timestamp_dt'][-1])\n",
    "    print(\"Val:\", val_df['timestamp_dt'][0], \"to\", val_df['timestamp_dt'][-1])\n",
    "    print(\"Test:\", test_df['timestamp_dt'][0], \"to\", test_df['timestamp_dt'][-1])\n",
    "    \n",
    "\n",
    "    params = {\n",
    "        # 模型结构参数\n",
    "        \"n_d\": 8,                      # 决策输出维度\n",
    "        \"n_a\": 8,                      # 注意力机制维度\n",
    "        \"n_steps\": 3,                  # 决策步数\n",
    "        \"gamma\": 1.3,                  # 控制特征复用的程度（>1）\n",
    "        \"n_independent\": 3,           # 每个 step 的独立 Feature Transformer 层数\n",
    "        \"n_shared\": 2,                # 每个 step 的共享 Feature Transformer 层数\n",
    "    \n",
    "        # 分类特征嵌入（如果你用的都是 float 特征，可以全留空）\n",
    "        \"cat_idxs\": cat_idxs,               # 类别特征的列索引\n",
    "        \"cat_dims\": cat_dims,               # 每个类别特征的类别数\n",
    "        \"cat_emb_dim\": cat_emb_dim,             # 类别特征的嵌入维度（或 list）\n",
    "    \n",
    "        # 正则化与数值稳定性\n",
    "        \"lambda_sparse\": 1e-4,        # 稀疏正则\n",
    "        \"epsilon\": 1e-15,             # sparsemax 稳定项\n",
    "        \"momentum\": 0.03,             # BatchNorm 的动量\n",
    "        \"clip_value\": 3.0,            # 梯度裁剪\n",
    "        \n",
    "        # 注意力 mask 类型\n",
    "        \"mask_type\": \"sparsemax\",     # sparsemax 或 entmax\n",
    "    \n",
    "        # 优化器设置（函数和参数）\n",
    "        # \"optimizer_fn\": torch.optim.Adam,    \n",
    "        \"optimizer_params\": {\"lr\": 5e-4},\n",
    "    \n",
    "        # 学习率调度器（可选）\n",
    "        \"scheduler_fn\": None,         # torch.optim.lr_scheduler.StepLR 等\n",
    "        \"scheduler_params\": {},       # 比如 {\"step_size\": 20, \"gamma\": 0.95}\n",
    "    \n",
    "        # 预训练解码器结构（一般用不到）\n",
    "        \"n_shared_decoder\": 1,\n",
    "        \"n_indep_decoder\": 1,\n",
    "    \n",
    "        # 训练环境和调试\n",
    "        \"seed\": 7,\n",
    "        \"verbose\": 1,\n",
    "        \"device_name\": \"cuda\",        # auto / cpu / cuda\n",
    "    }\n",
    "\n",
    "    init_fit_params = {\n",
    "        \"eval_metric\": ['mse'],\n",
    "        \"max_epochs\": 50,\n",
    "        \"patience\": 20,\n",
    "        \"batch_size\": 2048,\n",
    "        \"virtual_batch_size\": 512,\n",
    "        \"compute_importance\": False,\n",
    "    }\n",
    "\n",
    "    inc_fit_params = {\n",
    "        \"eval_metric\": ['mse'],\n",
    "        \"max_epochs\": 500,\n",
    "        \"patience\": 50,\n",
    "        \"batch_size\": 2048,\n",
    "        \"virtual_batch_size\": 512,\n",
    "        \"compute_importance\": False,\n",
    "        \"warm_start\": True,\n",
    "    }\n",
    "\n",
    "    \n",
    "    # if i == 0:\n",
    "    tabnet = TabNetRegressor(**params )\n",
    "    tabnet.fit(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        **init_fit_params,\n",
    "    )\n",
    "    # else:\n",
    "    #     tabnet.fit(\n",
    "    #         X_train=X_train,\n",
    "    #         y_train=y_train,\n",
    "    #         eval_set=[(X_val, y_val)],\n",
    "    #         **inc_fit_params,\n",
    "    #     )\n",
    "\n",
    "    y_pred = tabnet.predict(X_test).squeeze()\n",
    "    print(ts_test.shape, y_test.shape, y_pred.shape, px_test.shape)\n",
    "\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_pred):.6f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred):.6f}\")\n",
    "    current_window_results = {\n",
    "        'timestamp': ts_test,\n",
    "        'symbol_enc': sb_test, # 收集价格，回测时需要\n",
    "        'true_label': y_test,\n",
    "        'predicted_prob': y_pred,\n",
    "        'px': px_test, # 收集价格，回测时需要\n",
    "    }\n",
    "    \n",
    "    all_preds.append(current_window_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e498f-f9a6-4026-bc78-4321cf9b7eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74ec55-a5a5-4ac8-b278-0240c8c5accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"all_preds length: {len(all_preds)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098d5f8-9d85-403d-a94c-9952fc74e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_cross_section_comparison(symbols, true_labels, pred_probs, prices, std_array=None, alpha=1):\n",
    "    \"\"\"\n",
    "    symbols: list/array of symbol names或编码（横轴）\n",
    "    true_labels: array，对应每个币种的真实标签\n",
    "    pred_probs: array，对应每个币种的预测概率\n",
    "    prices: array，对应每个币种的价格\n",
    "    std_array: array，可选，价格的波动区间\n",
    "    alpha: 标准差放大倍数\n",
    "    \"\"\"\n",
    "    x = np.arange(len(symbols))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "    # 真实标签（可以用点图）\n",
    "    ax1.scatter(x, true_labels, label=\"True Label\", color='tab:blue', marker='o', s=50, alpha=0.7)\n",
    "    ax1.set_ylabel(\"True Label\", color='tab:blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax1.set_ylim(min(true_labels)*1.1, max(true_labels)*1.1)\n",
    "\n",
    "    # 预测概率\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x, pred_probs, label=\"Predicted Probability\", color='tab:green', marker='x', linestyle='-', alpha=0.7)\n",
    "    ax2.set_ylabel(\"Predicted Probability\", color='tab:green')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    # 价格\n",
    "    ax3 = ax1.twinx()\n",
    "    ax3.spines.right.set_position((\"outward\", 60))\n",
    "    ax3.plot(x, prices, label=\"Price\", color='tab:red', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # 价格区间带\n",
    "    if std_array is not None:\n",
    "        ax3.fill_between(x, prices - alpha * std_array, prices + alpha * std_array,\n",
    "                         color='tab:red', alpha=0.15, label=\"Price ± std\")\n",
    "\n",
    "    ax3.set_ylabel(\"Price\", color='tab:red')\n",
    "    ax3.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    # 横轴是币种名\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(symbols, rotation=45, ha='right')\n",
    "\n",
    "    plt.title(\"Cross-Sectional Comparison: True Label, Prediction & Price\")\n",
    "    # 合并图例\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    lines_3, labels_3 = ax3.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2 + lines_3, labels_1 + labels_2 + labels_3, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37709e65-e595-40a2-855a-93840255faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_list = []\n",
    "for i, result in enumerate(all_preds):\n",
    "    try:\n",
    "        # 先处理 symbol_enc 转成 numpy array\n",
    "        # 假设 result['symbol_enc'] 是 Polars DataFrame，列名是 'enc_cat_symbol'\n",
    "        if hasattr(result['symbol_enc'], \"to_pandas\"):\n",
    "            symbol_enc_array = result['symbol_enc'].to_pandas()['enc_cat_symbol'].values\n",
    "        else:\n",
    "            # 如果已经是 np.ndarray 或 list\n",
    "            symbol_enc_array = result['symbol_enc']\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'timestamp': result['timestamp'].squeeze(),  # (N,)\n",
    "            'symbol_enc': symbol_enc_array.squeeze(),    # (N,)\n",
    "            'true_label': result['true_label'].squeeze(),\n",
    "            'predicted_prob': result['predicted_prob'].squeeze(),\n",
    "            'px': result['px'].squeeze()\n",
    "        })\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"Warning: Empty dataframe at index {i}\")\n",
    "            continue\n",
    "        df_list.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {i}: {e}\")\n",
    "\n",
    "full_df = pd.concat(df_list, ignore_index=True)\n",
    "print(full_df.shape)\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede02bb-ee15-42ab-9d4a-77d449fac495",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f7817-6ddc-4f7c-9b5a-333820f897a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_analysis(factor_name, weekly_dataframes, target_col, num_bins=5):\n",
    "    bin_returns = [0.0] * num_bins\n",
    "    bin_counts = [0] * num_bins\n",
    "\n",
    "    for df in weekly_dataframes:\n",
    "        if factor_name not in df.columns or target_col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        sub_df = df.select([factor_name, target_col]).drop_nulls().to_pandas()\n",
    "        if len(sub_df) < num_bins:\n",
    "            continue\n",
    "\n",
    "        sub_df[\"bin\"] = pd.qcut(sub_df[factor_name], q=num_bins, labels=False, duplicates=\"drop\")\n",
    "        for i in range(num_bins):\n",
    "            group = sub_df[sub_df[\"bin\"] == i]\n",
    "            if not group.empty:\n",
    "                bin_returns[i] += group[target_col].mean()\n",
    "                bin_counts[i] += 1\n",
    "\n",
    "    avg_returns = [r / c if c > 0 else 0 for r, c in zip(bin_returns, bin_counts)]\n",
    "    return avg_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc0c0b-efbd-43d7-a5db-52d4c4a63f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def calc_ic_per_factor(weekly_dataframes, feature_cols, target_col):\n",
    "    ic_records = []\n",
    "\n",
    "    for feature in feature_cols:\n",
    "        ic_list = []\n",
    "        for df in weekly_dataframes:\n",
    "            if feature not in df.columns or target_col not in df.columns:\n",
    "                continue\n",
    "\n",
    "            sub_df = df.select([feature, target_col]).drop_nulls().to_pandas()\n",
    "            if len(sub_df) < 5:\n",
    "                continue\n",
    "\n",
    "            rank_ic, _ = spearmanr(sub_df[feature], sub_df[target_col])\n",
    "            if pd.notna(rank_ic):\n",
    "                ic_list.append(rank_ic)\n",
    "\n",
    "        if ic_list:\n",
    "            ic_mean = sum(ic_list) / len(ic_list)\n",
    "            ic_std = pd.Series(ic_list).std()\n",
    "            ic_ir = ic_mean / ic_std if ic_std > 1e-6 else 0\n",
    "            ic_records.append({\n",
    "                'factor': feature,\n",
    "                'IC Mean': ic_mean,\n",
    "                'IC Std': ic_std,\n",
    "                'IC IR': ic_ir\n",
    "            })\n",
    "\n",
    "    ic_df = pd.DataFrame(ic_records).sort_values(by='IC IR', ascending=False)\n",
    "    return ic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480d2ef-65e6-4bd4-8151-ce670f895d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_df = calc_ic_per_factor(weekly_dataframes, feature_cols, target_col)\n",
    "print(\"Top10 IC 因子：\")\n",
    "print(ic_df.head(10))\n",
    "\n",
    "top_factors = ic_df.head(10)['factor'].tolist()\n",
    "for factor in top_factors:\n",
    "    returns = bin_analysis(factor, weekly_dataframes, target_col, num_bins=5)\n",
    "    print(f\"Factor: {factor}, 分桶收益: {returns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05a3ad-e8b0-4490-bf87-beb402bdddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(16, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, factor in enumerate(top_factors):\n",
    "    returns = bin_analysis(factor, weekly_dataframes, target_col, num_bins=50)\n",
    "    axes[i].bar(range(1, 1 + len(returns)), returns)\n",
    "    axes[i].set_title(f\"Factor: {factor}\")\n",
    "    axes[i].set_xlabel(\"Bin\")\n",
    "    axes[i].set_ylabel(\"Mean Return\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1c350-e67c-4f47-a1b4-948110c33827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"总样本数：\", len(full_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e2dee-fc93-4173-9b41-553d46cc9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设你已有 df，包含 symbol_enc、timestamp、true_label、predicted_prob、px、position（自行添加）\n",
    "# 转换 timestamp 为时间格式（如需要）\n",
    "df = full_df\n",
    "df[\"timestamp\"] = pd.to_datetime(full_df[\"timestamp\"], unit=\"ms\")\n",
    "\n",
    "# 遍历每个币种\n",
    "symbols = df[\"symbol_enc\"].unique()\n",
    "fig, axs = plt.subplots(len(symbols), 1, figsize=(14, 3 * len(symbols)), sharex=True)\n",
    "\n",
    "if len(symbols) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "for i, sym in enumerate(symbols):\n",
    "    sym_df = df[df[\"symbol_enc\"] == sym].copy()\n",
    "    \n",
    "    ax = axs[i]\n",
    "    ax.set_title(f\"Symbol {sym}\")\n",
    "    \n",
    "    # 主轴: 价格\n",
    "    ax.plot(sym_df[\"timestamp\"], sym_df[\"px\"], label=\"Price\", color=\"black\")\n",
    "    ax.set_ylabel(\"Price\", color=\"black\")\n",
    "    ax.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "    # 第二轴: label\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(sym_df[\"timestamp\"], sym_df[\"true_label\"], label=\"Label\", color=\"blue\", alpha=0.6)\n",
    "    ax2.set_ylabel(\"Label\", color=\"blue\")\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    # 第三轴: predicted prob\n",
    "    ax3 = ax.twinx()\n",
    "    ax3.spines.right.set_position((\"axes\", 1.1))  # 偏移右边\n",
    "    ax3.plot(sym_df[\"timestamp\"], sym_df[\"predicted_prob\"], label=\"Pred Prob\", color=\"orange\", alpha=0.6)\n",
    "    ax3.set_ylabel(\"Predicted\", color=\"orange\")\n",
    "    ax3.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "    # 第四轴: position（如果你有这个字段）\n",
    "    if \"position\" in sym_df.columns:\n",
    "        ax4 = ax.twinx()\n",
    "        ax4.spines.right.set_position((\"axes\", 1.2))  # 更偏移右边\n",
    "        ax4.plot(sym_df[\"timestamp\"], sym_df[\"position\"], label=\"Position\", color=\"green\", alpha=0.6)\n",
    "        ax4.set_ylabel(\"Position\", color=\"green\")\n",
    "        ax4.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433617ae-5a7f-4a79-8f3b-5ed533b84ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "ic_list = []\n",
    "time_list = []\n",
    "\n",
    "# 计算每个时间截面的 IC\n",
    "for ts, group in tqdm(full_df.groupby('timestamp'), total=full_df['timestamp'].nunique(), desc=\"Calculating IC\"):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    if group['predicted_prob'].nunique() < 2 or group['true_label'].nunique() < 2:\n",
    "        continue\n",
    "    ic, _ = spearmanr(group['predicted_prob'], group['true_label'])\n",
    "    ic_list.append(ic)\n",
    "    time_list.append(ts)\n",
    "\n",
    "# 转为 np.array 和 datetime 格式（如需要）\n",
    "ic_array = np.array(ic_list)\n",
    "time_array = np.array(time_list)\n",
    "\n",
    "# 排序时间（可选，保险做法）\n",
    "sorted_idx = np.argsort(time_array)\n",
    "time_array = time_array[sorted_idx]\n",
    "ic_array = ic_array[sorted_idx]\n",
    "\n",
    "# 计算累计 IC（cum IC）\n",
    "cum_ic = np.cumsum(ic_array)\n",
    "\n",
    "# 计算 IR（信息比率 = 平均IC / IC标准差）\n",
    "ir = np.mean(ic_array) / np.std(ic_array)\n",
    "\n",
    "# 打印信息\n",
    "print(f\"平均IC: {np.mean(ic_array):.4f}\")\n",
    "print(f\"平均IC std: {np.std(ic_array):.4f}\")\n",
    "\n",
    "print(f\"信息比率 IR: {ir:.4f}\")\n",
    "\n",
    "# 每隔500点采样一次\n",
    "step = 500\n",
    "time_array_sampled = time_array[::step]\n",
    "ic_array_sampled = ic_array[::step]\n",
    "cum_ic_sampled = cum_ic[::step]\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# 子图1: IC 时间序列图（采样后）\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time_array_sampled, ic_array_sampled, marker='o', label='IC')\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.title(\"Information Coefficient (IC) over Time (sampled every 500 points)\")\n",
    "plt.ylabel(\"IC\")\n",
    "plt.legend()\n",
    "\n",
    "# 子图2: 累积 IC 图（采样后）\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time_array_sampled, cum_ic_sampled, color='orange', label='Cumulative IC')\n",
    "plt.title(f\"Cumulative IC (IR={ir:.4f})\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Cumulative IC\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfe395-3407-4797-ade7-fde243bfa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # 用于显示进度条\n",
    "\n",
    "# --- 假设 full_df 已经包含以下列 ---\n",
    "# - 'timestamp': 原始时间戳（例如毫秒），唯一且递增\n",
    "# - 'symbol_enc': 币种编码\n",
    "# - 'px': 当期价格\n",
    "# - 'predicted_label': 模型预测的标签（分类或排名），越大表示越好\n",
    "\n",
    "# --- 配置参数 ---\n",
    "N_INTERVAL = N # 调仓周期，每 N_INTERVAL 个时间戳调仓一次\n",
    "\n",
    "# N_INTERVAL = 1000 # 调仓周期，每 N_INTERVAL 个时间戳调仓一次\n",
    "\n",
    "# --- 数据预处理 ---\n",
    "# 1. 转换时间戳为 datetime 类型，方便处理和绘图\n",
    "bt_df = full_df\n",
    "bt_df['dt'] = pd.to_datetime(full_df['timestamp'], unit='ms')\n",
    "\n",
    "# 2. 确保数据按时间戳和币种排序，这是后续分组和shift操作的基础\n",
    "bt_df = bt_df.sort_values(['dt', 'symbol_enc']).reset_index(drop=True)\n",
    "\n",
    "# 3. 获取所有唯一的、排序后的时间戳列表\n",
    "timestamps_sorted = bt_df['dt'].drop_duplicates().sort_values().to_list()\n",
    "\n",
    "# 4. 确定所有调仓时间点\n",
    "rebalance_times = timestamps_sorted[::N_INTERVAL]\n",
    "\n",
    "# --- 识别多空信号（在每个调仓时间点）---\n",
    "# 记录每个调仓时间点应持有的多空币种\n",
    "rebalance_signals = {}\n",
    "for t in tqdm(rebalance_times, desc=\"Identifying Rebalance Signals\"):\n",
    "    # 筛选出当前调仓时间点 t 的所有币种数据（截面数据）\n",
    "    current_snapshot = bt_df[bt_df['dt'] == t]\n",
    "    if current_snapshot.empty:\n",
    "        continue\n",
    "\n",
    "    # 找出 predicted_label 最高（最好）和最低（最差）的币种\n",
    "    # 使用 .idxmax() 和 .idxmin() 找到索引，再用 .loc[] 提取 symbol_enc\n",
    "    long_symbol = current_snapshot.loc[current_snapshot['predicted_prob'].idxmax(), 'symbol_enc']\n",
    "    short_symbol = current_snapshot.loc[current_snapshot['predicted_prob'].idxmin(), 'symbol_enc']\n",
    "\n",
    "    rebalance_signals[t] = {'long': long_symbol, 'short': short_symbol}\n",
    "\n",
    "# --- 构建调仓周期内的持仓和计算周期收益 ---\n",
    "# 存储每个调仓周期的策略收益\n",
    "period_returns = []\n",
    "\n",
    "# 初始化当前持仓，确保从第一个调仓点开始生效\n",
    "current_long_symbol = None\n",
    "current_short_symbol = None\n",
    "\n",
    "# 遍历每个调仓周期\n",
    "for i in tqdm(range(len(rebalance_times)), desc=\"Calculating Period Returns\"):\n",
    "    start_time = rebalance_times[i]\n",
    "    # 确定当前调仓周期结束时间\n",
    "    end_time = rebalance_times[i+1] if i + 1 < len(rebalance_times) else timestamps_sorted[-1]\n",
    "\n",
    "    # 从 rebalance_signals 获取当前周期的多空币种\n",
    "    if start_time in rebalance_signals:\n",
    "        current_long_symbol = rebalance_signals[start_time]['long']\n",
    "        current_short_symbol = rebalance_signals[start_time]['short']\n",
    "    else:\n",
    "        # 如果当前调仓点没有信号（不应发生），则沿用上一个周期的头寸或保持空仓\n",
    "        # 这里为了简化，假设如果有信号就会找到，没有则保持上一个有效头寸\n",
    "        # 如果需要严格空仓，可以在这里设置 current_long_symbol = None, current_short_symbol = None\n",
    "        pass\n",
    "\n",
    "    # 如果没有有效头寸，跳过此周期（收益为0）\n",
    "    if current_long_symbol is None or current_short_symbol is None:\n",
    "        period_returns.append({'dt': start_time, 'strategy_log_return': 0.0})\n",
    "        continue\n",
    "\n",
    "    # 筛选出当前调仓周期内的所有数据\n",
    "    # 包括起始时间点（进行调仓），但不包括结束时间点（结算）\n",
    "    period_data = bt_df[(bt_df['dt'] >= start_time) & (bt_df['dt'] <= end_time)].copy()\n",
    "\n",
    "    # 获取多头和空头币种在该周期开始和结束时的价格\n",
    "    long_start_px = period_data[(period_data['dt'] == start_time) & (period_data['symbol_enc'] == current_long_symbol)]['px'].iloc[0]\n",
    "    long_end_px = period_data[(period_data['dt'] == end_time) & (period_data['symbol_enc'] == current_long_symbol)]['px'].iloc[0]\n",
    "\n",
    "    short_start_px = period_data[(period_data['dt'] == start_time) & (period_data['dt'] <= end_time) & (period_data['symbol_enc'] == current_short_symbol)]['px'].iloc[0]\n",
    "    short_end_px = period_data[(period_data['dt'] == end_time) & (period_data['dt'] <= end_time) & (period_data['symbol_enc'] == current_short_symbol)]['px'].iloc[0]\n",
    "\n",
    "    # 计算多头和空头在该周期内的对数收益率\n",
    "    long_log_ret = np.log(long_end_px) - np.log(long_start_px)\n",
    "    short_log_ret = np.log(short_end_px) - np.log(short_start_px)\n",
    "\n",
    "    # 计算策略在该周期内的总对数收益（多头收益 + 空头收益的绝对值）\n",
    "    # 假设各持仓权重相等，所以是 (多头收益 - 空头收益) / 2\n",
    "    # 或者说，做多一个，做空一个，组合总收益\n",
    "    strategy_period_log_return = (long_log_ret - short_log_ret) / 2 # 平均对冲策略\n",
    "\n",
    "    period_returns.append({\n",
    "        'dt': start_time,\n",
    "        'strategy_log_return': strategy_period_log_return\n",
    "    })\n",
    "\n",
    "# 将周期收益转换为 DataFrame\n",
    "strategy_returns_df = pd.DataFrame(period_returns).set_index('dt')\n",
    "strategy_returns_series = strategy_returns_df['strategy_log_return']\n",
    "\n",
    "# --- 绩效指标函数 ---\n",
    "def perf_stats(return_series, periods_per_year):\n",
    "    \"\"\"\n",
    "    计算并返回策略的绩效统计数据。\n",
    "    return_series: 每个周期的对数收益率序列。\n",
    "    periods_per_year: 一年内有多少个这样的周期（用于年化）。\n",
    "    \"\"\"\n",
    "    if return_series.empty:\n",
    "        return {\n",
    "            'Cumulative Return': np.nan, 'Annualized Return': np.nan,\n",
    "            'Annualized Volatility': np.nan, 'Sharpe Ratio': np.nan, 'Max Drawdown': np.nan\n",
    "        }\n",
    "\n",
    "    cum_ret = return_series.cumsum().apply(np.exp) # 对数收益累加后转回普通收益\n",
    "    total_return = cum_ret.iloc[-1] - 1 # 累计普通收益\n",
    "\n",
    "    # 年化收益率 (几何平均)\n",
    "    num_periods = len(return_series)\n",
    "    if num_periods > 0:\n",
    "        ann_return = (cum_ret.iloc[-1])**(periods_per_year / num_periods) - 1\n",
    "    else:\n",
    "        ann_return = np.nan\n",
    "\n",
    "    ann_vol = return_series.std() * np.sqrt(periods_per_year) # 年化波动率\n",
    "    sharpe = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "    # 最大回撤 (基于普通收益)\n",
    "    running_max = cum_ret.cummax()\n",
    "    drawdown = (cum_ret - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    return {\n",
    "        'Cumulative Return': total_return,\n",
    "        'Annualized Return': ann_return,\n",
    "        'Annualized Volatility': ann_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Max Drawdown': max_dd\n",
    "    }\n",
    "\n",
    "# --- 计算和展示绩效 ---\n",
    "# 假设每个时间戳是10分钟，N_INTERVAL=1000，则一个周期是 1000 * 10分钟 = 10000 分钟\n",
    "# 一年大约有 52560 个10分钟的间隔 (365天 * 24小时 * 6个10分钟/小时)\n",
    "# 则一年大约有 52560 / 1000 = 52.56 个 N_INTERVAL 周期\n",
    "periods_per_year_for_annualization = (365 * 24 * 60) / (N_INTERVAL * 10) # 10分钟一档\n",
    "# 或者更直接： (总时间戳数 / N_INTERVAL) / 总年数\n",
    "\n",
    "stats = perf_stats(strategy_returns_series, periods_per_year_for_annualization)\n",
    "print(\"\\n--- Strategy Performance Statistics ---\")\n",
    "print(pd.Series(stats))\n",
    "\n",
    "# --- 绘制累计收益曲线 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "# 对数收益累加，然后取指数，得到累计普通收益曲线\n",
    "strategy_returns_series.cumsum().apply(np.exp).plot()\n",
    "plt.title(f\"Long-Short Strategy Cumulative Return (Rebalance every {N_INTERVAL} bars)\")\n",
    "plt.xlabel(\"Rebalance Timestamp\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b8da1-39d5-494b-b3c4-13eaadf19d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 假设 full_df 已经包含以下列 ---\n",
    "# - 'timestamp'（时间戳，可转为 datetime）\n",
    "# - 'symbol_enc'（币种编码）\n",
    "# - 'px'（当期价格）\n",
    "# - 'predicted_label'（模型预测的 rank_label，0=最差、3=最好，或你自己定义的分类）\n",
    "\n",
    "# --- 配置参数 ---\n",
    "N_INTERVAL = N # 调仓周期，每 N_INTERVAL 个时间戳调仓一次\n",
    "# N_INTERVAL = 1000 # 调仓周期，每 N_INTERVAL 个时间戳调仓一次\n",
    "N_LONG = 2         # 做多的品种数量（例如，前2个最好的）\n",
    "N_SHORT = 2       # 做空的品种数量（例如，后2个最差的）\n",
    "\n",
    "# --- 数据预处理 ---\n",
    "# 1. 转换时间戳为 datetime 类型，方便处理和绘图\n",
    "bt_df = full_df\n",
    "bt_df['dt'] = pd.to_datetime(bt_df['timestamp'], unit='ms')\n",
    "\n",
    "# 2. 确保数据按时间戳和币种排序，这是后续分组和shift操作的基础\n",
    "bt_df = bt_df.sort_values(['dt', 'symbol_enc']).reset_index(drop=True)\n",
    "\n",
    "# 3. 获取所有唯一的、排序后的时间戳列表\n",
    "timestamps_sorted = bt_df['dt'].drop_duplicates().sort_values().to_list()\n",
    "\n",
    "# 4. 确定所有调仓时间点\n",
    "rebalance_times = timestamps_sorted[::N_INTERVAL]\n",
    "\n",
    "# --- 识别多空信号（在每个调仓时间点）---\n",
    "# 记录每个调仓时间点应持有的多空币种列表\n",
    "rebalance_signals = {}\n",
    "for t in tqdm(rebalance_times, desc=\"Identifying Rebalance Signals\"):\n",
    "    current_snapshot = bt_df[bt_df['dt'] == t].copy() # 使用.copy()避免SettingWithCopyWarning\n",
    "    if current_snapshot.empty:\n",
    "        continue\n",
    "\n",
    "    # 根据 predicted_label 排序，选择前N_LONG和后N_SHORT个品种\n",
    "    # 降序排列找到最好的，升序排列找到最差的\n",
    "    sorted_by_prediction = current_snapshot.sort_values(by='predicted_prob', ascending=False)\n",
    "\n",
    "    # 选择前 N_LONG 个最好的品种做多\n",
    "    long_symbols = sorted_by_prediction.head(N_LONG)['symbol_enc'].tolist()\n",
    "    \n",
    "    # 选择后 N_SHORT 个最差的品种做空\n",
    "    # 注意：如果 N_LONG + N_SHORT > 总品种数，需要避免重复\n",
    "    # 确保做空品种与做多品种不重叠\n",
    "    short_symbols_potential = sorted_by_prediction.tail(N_SHORT)['symbol_enc'].tolist()\n",
    "    short_symbols = [s for s in short_symbols_potential if s not in long_symbols]\n",
    "\n",
    "    rebalance_signals[t] = {'long': long_symbols, 'short': short_symbols}\n",
    "\n",
    "# --- 构建调仓周期内的持仓和计算周期收益 ---\n",
    "# 存储每个调仓周期的策略收益\n",
    "period_returns = []\n",
    "\n",
    "# 初始化当前持仓，确保从第一个调仓点开始生效\n",
    "current_long_symbols = []\n",
    "current_short_symbols = []\n",
    "\n",
    "# 遍历每个调仓周期\n",
    "for i in tqdm(range(len(rebalance_times)), desc=\"Calculating Period Returns\"):\n",
    "    start_time = rebalance_times[i]\n",
    "    end_time = rebalance_times[i+1] if i + 1 < len(rebalance_times) else timestamps_sorted[-1]\n",
    "\n",
    "    # 获取当前周期的多空币种列表\n",
    "    if start_time in rebalance_signals:\n",
    "        current_long_symbols = rebalance_signals[start_time]['long']\n",
    "        current_short_symbols = rebalance_signals[start_time]['short']\n",
    "    else:\n",
    "        # 如果当前调仓点没有信号（不应发生），则沿用上一个周期的头寸或保持空仓\n",
    "        pass # 维持前一周期头寸\n",
    "\n",
    "    # 如果没有有效头寸（或数量不够），跳过此周期（收益为0）\n",
    "    if not current_long_symbols or not current_short_symbols:\n",
    "        period_returns.append({'dt': start_time, 'strategy_log_return': 0.0})\n",
    "        continue\n",
    "\n",
    "    # 筛选出当前调仓周期内的所有数据\n",
    "    period_data = bt_df[(bt_df['dt'] >= start_time) & (bt_df['dt'] <= end_time)].copy()\n",
    "\n",
    "    total_period_log_return = 0.0\n",
    "\n",
    "    # 计算多头组合收益\n",
    "    long_portfolio_log_return = 0.0\n",
    "    for symbol in current_long_symbols:\n",
    "        try:\n",
    "            long_start_px = period_data[(period_data['dt'] == start_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "            long_end_px = period_data[(period_data['dt'] == end_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "            long_portfolio_log_return += (np.log(long_end_px) - np.log(long_start_px))\n",
    "        except IndexError:\n",
    "            # 币种数据缺失处理\n",
    "            # print(f\"Warning: Data for {symbol} missing at {start_time} or {end_time}\")\n",
    "            pass # 或者采取其他更严格的缺失处理方式\n",
    "\n",
    "    # 计算空头组合收益\n",
    "    short_portfolio_log_return = 0.0\n",
    "    for symbol in current_short_symbols:\n",
    "        try:\n",
    "            short_start_px = period_data[(period_data['dt'] == start_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "            short_end_px = period_data[(period_data['dt'] == end_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "            short_portfolio_log_return += (np.log(short_end_px) - np.log(short_start_px))\n",
    "        except IndexError:\n",
    "            # 币种数据缺失处理\n",
    "            # print(f\"Warning: Data for {symbol} missing at {start_time} or {end_time}\")\n",
    "            pass # 或者采取其他更严格的缺失处理方式\n",
    "\n",
    "    # 平均权重计算组合收益：(多头组合收益 - 空头组合收益) / 总持仓品种数\n",
    "    # 假设每个选中的品种权重相等\n",
    "    num_traded_symbols = len(current_long_symbols) + len(current_short_symbols)\n",
    "    if num_traded_symbols > 0:\n",
    "        total_period_log_return = (long_portfolio_log_return - short_portfolio_log_return) / num_traded_symbols\n",
    "    else:\n",
    "        total_period_log_return = 0.0 # 没有有效交易则收益为0\n",
    "\n",
    "    period_returns.append({\n",
    "        'dt': start_time,\n",
    "        'strategy_log_return': total_period_log_return\n",
    "    })\n",
    "\n",
    "# 将周期收益转换为 DataFrame\n",
    "strategy_returns_df = pd.DataFrame(period_returns).set_index('dt')\n",
    "strategy_returns_series = strategy_returns_df['strategy_log_return']\n",
    "\n",
    "# --- 绩效指标函数 (与之前相同，但强调基于周期性收益) ---\n",
    "def perf_stats(return_series, periods_per_year):\n",
    "    if return_series.empty:\n",
    "        return {\n",
    "            'Cumulative Return': np.nan, 'Annualized Return': np.nan,\n",
    "            'Annualized Volatility': np.nan, 'Sharpe Ratio': np.nan, 'Max Drawdown': np.nan\n",
    "        }\n",
    "\n",
    "    cum_ret = return_series.cumsum().apply(np.exp)\n",
    "    total_return = cum_ret.iloc[-1] - 1\n",
    "\n",
    "    num_periods = len(return_series)\n",
    "    if num_periods > 0:\n",
    "        ann_return = (cum_ret.iloc[-1])**(periods_per_year / num_periods) - 1\n",
    "    else:\n",
    "        ann_return = np.nan\n",
    "\n",
    "    ann_vol = return_series.std() * np.sqrt(periods_per_year)\n",
    "    sharpe = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "    running_max = cum_ret.cummax()\n",
    "    drawdown = (cum_ret - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    return {\n",
    "        'Cumulative Return': total_return,\n",
    "        'Annualized Return': ann_return,\n",
    "        'Annualized Volatility': ann_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Max Drawdown': max_dd\n",
    "    }\n",
    "\n",
    "# --- 计算和展示绩效 ---\n",
    "# 假设每个时间戳是10分钟，N_INTERVAL=1000，则一个周期是 1000 * 10分钟 = 10000 分钟\n",
    "# 则一年大约有 52560 / 1000 = 52.56 个 N_INTERVAL 周期\n",
    "periods_per_year_for_annualization = (365 * 24 * 60) / (N_INTERVAL * 10) # 10分钟一档\n",
    "# 请根据你的数据实际频率和 N_INTERVAL 重新计算此值！\n",
    "\n",
    "stats = perf_stats(strategy_returns_series, periods_per_year_for_annualization)\n",
    "print(\"\\n--- Strategy Performance Statistics ---\")\n",
    "print(pd.Series(stats))\n",
    "\n",
    "# --- 绘制累计收益曲线 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "strategy_returns_series.cumsum().apply(np.exp).plot()\n",
    "plt.title(f\"Long-Short Strategy Cumulative Return (Rebalance every {N_INTERVAL} bars, Long {N_LONG}, Short {N_SHORT})\")\n",
    "plt.xlabel(\"Rebalance Timestamp\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843c6c1-0789-410e-9bde-c8169cc67690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns # 用于绘制热力图\n",
    "\n",
    "# --- 假设 full_df 已经包含以下列 ---\n",
    "# - 'timestamp'（时间戳，可转为 datetime）\n",
    "# - 'symbol_enc'（币种编码）\n",
    "# - 'px'（当期价格）\n",
    "# - 'predicted_prob'（模型预测的概率，越大表示越好）\n",
    "\n",
    "# --- 配置参数 ---\n",
    "bt_df = full_df\n",
    "\n",
    "N_INTERVAL = N * 1 # 调仓周期，每 N_INTERVAL 个时间戳调仓一次\n",
    "N_LONG = 2    # 做多的品种数量\n",
    "N_SHORT = 2      # 做空的品种数量\n",
    "TRANSACTION_COST_PER_TRADE = 0.0002 / (N_LONG + N_SHORT)\n",
    "\n",
    "\n",
    "# --- 数据预处理 (与之前相同) ---\n",
    "bt_df['dt'] = pd.to_datetime(bt_df['timestamp'], unit='ms')\n",
    "bt_df = bt_df.sort_values(['dt', 'symbol_enc']).reset_index(drop=True)\n",
    "timestamps_sorted = bt_df['dt'].drop_duplicates().sort_values().to_list()\n",
    "rebalance_times = timestamps_sorted[::N_INTERVAL]\n",
    "\n",
    "# --- 识别多空信号（在每个调仓时间点）(与之前相同) ---\n",
    "rebalance_signals = {}\n",
    "for t in tqdm(rebalance_times, desc=\"Identifying Rebalance Signals\"):\n",
    "    current_snapshot = bt_df[bt_df['dt'] == t].copy()\n",
    "    if current_snapshot.empty:\n",
    "        continue\n",
    "\n",
    "    sorted_by_prediction = current_snapshot.sort_values(by='predicted_prob', ascending=False)\n",
    "    long_symbols = sorted_by_prediction.head(N_LONG)['symbol_enc'].tolist()\n",
    "    short_symbols_potential = sorted_by_prediction.tail(N_SHORT)['symbol_enc'].tolist()\n",
    "    short_symbols = [s for s in short_symbols_potential if s not in long_symbols]\n",
    "\n",
    "    rebalance_signals[t] = {'long': long_symbols, 'short': short_symbols}\n",
    "\n",
    "# --- 构建调仓周期内的持仓和计算周期收益 (与之前相同) ---\n",
    "period_results = []\n",
    "all_positions_by_period = []\n",
    "\n",
    "current_long_symbols = []\n",
    "current_short_symbols = []\n",
    "\n",
    "for i in tqdm(range(len(rebalance_times)), desc=\"Calculating Period Returns\"):\n",
    "    start_time = rebalance_times[i]\n",
    "    end_time = rebalance_times[i+1] if i + 1 < len(rebalance_times) else timestamps_sorted[-1]\n",
    "\n",
    "    prev_long_symbols = current_long_symbols[:]\n",
    "    prev_short_symbols = current_short_symbols[:]\n",
    "\n",
    "    if start_time in rebalance_signals:\n",
    "        current_long_symbols = rebalance_signals[start_time]['long']\n",
    "        current_short_symbols = rebalance_signals[start_time]['short']\n",
    "    \n",
    "    # --- 记录当前调仓周期所有品种的持仓状态 ---\n",
    "    all_unique_symbols = bt_df['symbol_enc'].unique()\n",
    "    current_period_positions = {symbol: 0 for symbol in all_unique_symbols}\n",
    "\n",
    "    for symbol in current_long_symbols:\n",
    "        current_period_positions[symbol] = 1\n",
    "\n",
    "    for symbol in current_short_symbols:\n",
    "        if current_period_positions[symbol] != 1:\n",
    "            current_period_positions[symbol] = -1\n",
    "\n",
    "    all_positions_by_period.append({'dt': start_time, **current_period_positions})\n",
    "\n",
    "    # --- 计算本周期的策略收益 (毛收益) ---\n",
    "    gross_period_log_return = 0.0\n",
    "    if not current_long_symbols or not current_short_symbols:\n",
    "        gross_period_log_return = 0.0\n",
    "    else:\n",
    "        period_data = bt_df[(bt_df['dt'] >= start_time) & (bt_df['dt'] <= end_time)].copy()\n",
    "\n",
    "        long_portfolio_log_return = 0.0\n",
    "        for symbol in current_long_symbols:\n",
    "            try:\n",
    "                long_start_px = period_data[(period_data['dt'] == start_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                long_end_px = period_data[(period_data['dt'] == end_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                long_portfolio_log_return += (np.log(long_end_px) - np.log(long_start_px))\n",
    "            except IndexError:\n",
    "                long_portfolio_log_return += 0.0\n",
    "                pass\n",
    "\n",
    "        short_portfolio_log_return = 0.0\n",
    "        for symbol in current_short_symbols:\n",
    "            try:\n",
    "                short_start_px = period_data[(period_data['dt'] == start_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                short_end_px = period_data[(period_data['dt'] == end_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                short_portfolio_log_return += (np.log(short_end_px) - np.log(short_start_px))\n",
    "            except IndexError:\n",
    "                short_portfolio_log_return += 0.0\n",
    "                pass\n",
    "\n",
    "        num_traded_symbols = len(current_long_symbols) + len(current_short_symbols)\n",
    "        if num_traded_symbols > 0:\n",
    "            gross_period_log_return = (long_portfolio_log_return - short_portfolio_log_return) / num_traded_symbols\n",
    "        else:\n",
    "            gross_period_log_return = 0.0\n",
    "\n",
    "    # --- 计算本周期的交易手续费 ---\n",
    "    transaction_cost_this_period = 0.0\n",
    "    if i > 0:\n",
    "        close_long_count = len([s for s in prev_long_symbols if s not in current_long_symbols])\n",
    "        close_short_count = len([s for s in prev_short_symbols if s not in current_short_symbols])\n",
    "        \n",
    "        open_long_count = len([s for s in current_long_symbols if s not in prev_long_symbols])\n",
    "        open_short_count = len([s for s in current_short_symbols if s not in prev_short_symbols])\n",
    "        \n",
    "        transaction_cost_this_period = (close_long_count + close_short_count + open_long_count + open_short_count) * TRANSACTION_COST_PER_TRADE\n",
    "    else:\n",
    "        transaction_cost_this_period = (len(current_long_symbols) + len(current_short_symbols)) * TRANSACTION_COST_PER_TRADE\n",
    "\n",
    "    net_period_log_return = gross_period_log_return - transaction_cost_this_period \n",
    "    \n",
    "    period_results.append({\n",
    "        'dt': start_time,\n",
    "        'gross_strategy_log_return': gross_period_log_return,\n",
    "        'transaction_cost': transaction_cost_this_period,\n",
    "        'net_strategy_log_return': net_period_log_return,\n",
    "        'num_long_positions': len(current_long_symbols),\n",
    "        'num_short_positions': len(current_short_symbols),\n",
    "        'long_symbols_list': current_long_symbols,\n",
    "        'short_symbols_list': current_short_symbols\n",
    "    })\n",
    "\n",
    "# 将周期结果转换为 DataFrame\n",
    "strategy_results_df = pd.DataFrame(period_results).set_index('dt')\n",
    "\n",
    "# --- 准备持仓热力图数据 ---\n",
    "positions_heatmap_df = pd.DataFrame(all_positions_by_period).set_index('dt')\n",
    "positions_heatmap_df = positions_heatmap_df[sorted(positions_heatmap_df.columns)]\n",
    "\n",
    "\n",
    "# --- 绩效指标函数 (与之前相同) ---\n",
    "def perf_stats(return_series, periods_per_year):\n",
    "    if return_series.empty:\n",
    "        return {\n",
    "            'Cumulative Return': np.nan, 'Annualized Return': np.nan,\n",
    "            'Annualized Volatility': np.nan, 'Sharpe Ratio': np.nan, 'Max Drawdown': np.nan\n",
    "        }\n",
    "\n",
    "    cum_ret = return_series.cumsum().apply(np.exp)\n",
    "    total_return = cum_ret.iloc[-1] - 1\n",
    "\n",
    "    num_periods = len(return_series)\n",
    "    if num_periods > 0:\n",
    "        ann_return = (cum_ret.iloc[-1])**(periods_per_year / num_periods) - 1\n",
    "    else:\n",
    "        ann_return = np.nan\n",
    "\n",
    "    ann_vol = return_series.std() * np.sqrt(periods_per_year)\n",
    "    sharpe = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "    running_max = cum_ret.cummax()\n",
    "    drawdown = (cum_ret - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    return {\n",
    "        'Cumulative Return': total_return,\n",
    "        'Annualized Return': ann_return,\n",
    "        'Annualized Volatility': ann_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Max Drawdown': max_dd\n",
    "    }\n",
    "\n",
    "# --- 计算和展示绩效 (与之前相同) ---\n",
    "periods_per_year_for_annualization = (365 * 24 * 60) / (N_INTERVAL * 10) \n",
    "\n",
    "print(\"\\n--- Strategy Performance Statistics (Gross) ---\")\n",
    "gross_stats = perf_stats(strategy_results_df['gross_strategy_log_return'], periods_per_year_for_annualization)\n",
    "print(pd.Series(gross_stats))\n",
    "\n",
    "print(\"\\n--- Strategy Performance Statistics (Net of Costs) ---\")\n",
    "net_stats = perf_stats(strategy_results_df['net_strategy_log_return'], periods_per_year_for_annualization)\n",
    "print(pd.Series(net_stats))\n",
    "\n",
    "print(f\"\\nTotal Transaction Cost (Sum of individual costs): {strategy_results_df['transaction_cost'].sum():.6f}\")\n",
    "\n",
    "# --- 绘制图表 (使用低饱和度配色) ---\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 22), sharex=False, gridspec_kw={'height_ratios': [0.35, 0.2, 0.2, 0.25]})\n",
    "\n",
    "# 定义低饱和度颜色\n",
    "# 可以选择 seaborn 的 palette，或者自定义 HEX 颜色\n",
    "# muted, pastel, dark, bright, deep, colorblind\n",
    "# 例如：sns.color_palette(\"muted\") 或 sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "# 曲线图颜色\n",
    "COLOR_GROSS_RETURN = sns.color_palette(\"Paired\")[1] # 柔和的蓝色\n",
    "COLOR_NET_RETURN = sns.color_palette(\"Paired\")[3]   # 柔和的绿色\n",
    "COLOR_TRANSACTION_COST = sns.color_palette(\"Paired\")[5] # 柔和的红色\n",
    "COLOR_LONG_POSITIONS = sns.color_palette(\"Paired\")[7] # 柔和的紫色\n",
    "COLOR_SHORT_POSITIONS = sns.color_palette(\"Paired\")[9] # 柔和的橙色\n",
    "\n",
    "# 热力图颜色映射 (低饱和度 RdBu)\n",
    "HEATMAP_CMAP = sns.diverging_palette(240, 10, as_cmap=True, s=70, l=60, sep=1) # 240 (蓝) 到 10 (红), 饱和度70, 亮度60, 分离度1\n",
    "# 其他可选的低饱和度发散型色图： 'coolwarm_r', 'Spectral_r', 'vlag', 'icefire'\n",
    "# 或者自定义一个更温和的 RdBu\n",
    "# HEATMAP_CMAP = plt.cm.get_cmap('RdBu', 3) # RdBu色图取3个离散值，可能需要进一步调低饱和度\n",
    "# HEATMAP_CMAP = LinearSegmentedColormap.from_list(\"mycmap\", [(0, \"darkred\"), (0.5, \"lightgray\"), (1, \"darkblue\")]) # 更精细自定义\n",
    "\n",
    "# 设置图表背景风格 (可选，例如设置为白色背景)\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # 或者 'seaborn-v0_8-pastel' / 'seaborn-v0_8-muted'\n",
    "\n",
    "\n",
    "# 子图1: 累计收益 (毛收益 vs. 净收益)\n",
    "strategy_results_df['gross_strategy_log_return'].cumsum().apply(np.exp).plot(ax=axes[0], label='Cumulative Gross Return', color=COLOR_GROSS_RETURN)\n",
    "strategy_results_df['net_strategy_log_return'].cumsum().apply(np.exp).plot(ax=axes[0], label='Cumulative Net Return', color=COLOR_NET_RETURN)\n",
    "axes[0].set_title(f\"Cumulative Strategy Returns (Rebalance every {N_INTERVAL} bars, Long {N_LONG}, Short {N_SHORT})\")\n",
    "axes[0].set_ylabel(\"Cumulative Return\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, linestyle=':', alpha=0.7) # 调整网格线样式和透明度\n",
    "axes[0].set_xlabel(\"\")\n",
    "\n",
    "# 子图2: 累计手续费消耗\n",
    "strategy_results_df['transaction_cost'].cumsum().plot(ax=axes[1], label='Cumulative Transaction Cost', color=COLOR_TRANSACTION_COST)\n",
    "axes[1].set_title(\"Cumulative Transaction Cost Over Time\")\n",
    "axes[1].set_ylabel(\"Total Cost\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, linestyle=':', alpha=0.7)\n",
    "axes[1].set_xlabel(\"\")\n",
    "\n",
    "# 子图3: 持仓数量变化 (保留，作为快速概览)\n",
    "strategy_results_df['num_long_positions'].plot(ax=axes[2], label='Number of Long Positions', color=COLOR_LONG_POSITIONS, drawstyle='steps-post')\n",
    "strategy_results_df['num_short_positions'].plot(ax=axes[2], label='Number of Short Positions', color=COLOR_SHORT_POSITIONS, drawstyle='steps-post')\n",
    "axes[2].set_title(\"Number of Long and Short Positions Over Time (Overview)\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "axes[2].set_xlabel(\"\")\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, linestyle=':', alpha=0.7)\n",
    "axes[2].set_ylim(bottom=0)\n",
    "\n",
    "# 子图4: 详细持仓热力图\n",
    "if not positions_heatmap_df.empty:\n",
    "    sns.heatmap(\n",
    "        positions_heatmap_df.T,\n",
    "        cmap=HEATMAP_CMAP, # 使用新的低饱和度色图\n",
    "        cbar_kws={'ticks': [-1, 0, 1], 'label': 'Position Status (-1: Short, 0: None, 1: Long)'},\n",
    "        ax=axes[3],\n",
    "        yticklabels=True,\n",
    "        xticklabels=True,\n",
    "        linewidths=0.5, # 增加网格线\n",
    "        linecolor='lightgray' # 网格线颜色\n",
    "    )\n",
    "    axes[3].set_title(\"Detailed Position Status Heatmap (Per Symbol)\")\n",
    "    axes[3].set_xlabel(\"Rebalance Timestamp\")\n",
    "    axes[3].set_ylabel(\"Symbol\")\n",
    "    \n",
    "    # 调整x轴刻度标签，避免重叠\n",
    "    num_ticks = 10 \n",
    "    if len(positions_heatmap_df.index) > num_ticks:\n",
    "        tick_interval = len(positions_heatmap_df.index) // num_ticks\n",
    "        axes[3].set_xticks(np.arange(0, len(positions_heatmap_df.index), tick_interval))\n",
    "        axes[3].set_xticklabels(positions_heatmap_df.index[::tick_interval].strftime('%Y-%m-%d %H:%M'))\n",
    "    else:\n",
    "        axes[3].set_xticklabels(positions_heatmap_df.index.strftime('%Y-%m-%d %H:%M'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36ef44-90b9-42a3-b30a-f22871ffd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns # 用于绘制热力图\n",
    "\n",
    "# --- 假设 full_df 已经包含以下列 ---\n",
    "# - 'timestamp'（时间戳，可转为 datetime）\n",
    "# - 'symbol_enc'（币种编码）\n",
    "# - 'px'（当期价格）\n",
    "# - 'predicted_prob'（模型预测的概率，越大表示越好）\n",
    "\n",
    "# --- 配置参数 ---\n",
    "# 注意：你的原始代码中 bt_df = full_df，这里假设 full_df 已经被传入或定义\n",
    "# 如果 full_df 是一个未定义的变量，你需要在这里定义或加载它\n",
    "# 例如：bt_df = pd.read_csv('your_data.csv')\n",
    "# 或者 bt_df = full_df # 如果 full_df 在此脚本外部定义\n",
    "\n",
    "# 这里N是一个未定义的变量，你需要给它一个具体的值，例如 100\n",
    "bt_df = full_df \n",
    "\n",
    "\n",
    "N_INTERVAL = N * 4 # 调仓周期，每 N_INTERVAL 个时间戳调仓一次\n",
    "# N_INTERVAL = 2000\n",
    "N_LONG = 4       # 做多的品种数量\n",
    "N_SHORT = 4        # 做空的品种数量\n",
    "TRANSACTION_COST_PER_TRADE = 0.001 / (N_LONG + N_SHORT)\n",
    "\n",
    "# 新增：单币种止损参数\n",
    "STOP_LOSS_PERCENT = 0.15 # 单币种止损百分比，例如 0.05 表示 5% 的亏损止损\n",
    "\n",
    "# --- 数据预处理 ---\n",
    "bt_df['dt'] = pd.to_datetime(bt_df['timestamp'], unit='ms')\n",
    "bt_df = bt_df.sort_values(['dt', 'symbol_enc']).reset_index(drop=True)\n",
    "timestamps_sorted = bt_df['dt'].drop_duplicates().sort_values().to_list()\n",
    "rebalance_times = timestamps_sorted[::N_INTERVAL]\n",
    "\n",
    "# --- 识别多空信号（在每个调仓时间点）---\n",
    "rebalance_signals = {}\n",
    "for t in tqdm(rebalance_times, desc=\"Identifying Rebalance Signals\"):\n",
    "    current_snapshot = bt_df[bt_df['dt'] == t].copy()\n",
    "    if current_snapshot.empty:\n",
    "        rebalance_signals[t] = {'long': [], 'short': [], 'prices': {}} # 增加prices字典\n",
    "        continue\n",
    "\n",
    "    # 根据预测值排序\n",
    "    sorted_by_prediction = current_snapshot.sort_values(by='predicted_prob', ascending=False)\n",
    "    \n",
    "    # 选择多头和空头品种\n",
    "    long_symbols = sorted_by_prediction.head(N_LONG)['symbol_enc'].tolist()\n",
    "    short_symbols_potential = sorted_by_prediction.tail(N_SHORT)['symbol_enc'].tolist()\n",
    "    \n",
    "    # 确保做空品种不与做多品种重复\n",
    "    short_symbols = [s for s in short_symbols_potential if s not in long_symbols]\n",
    "\n",
    "    # !!! 强制多空同时开仓 !!!\n",
    "    if not long_symbols or not short_symbols:\n",
    "        rebalance_signals[t] = {'long': [], 'short': [], 'prices': {}}\n",
    "    else:\n",
    "        # 记录开仓时的价格\n",
    "        prices = {}\n",
    "        for symbol in long_symbols:\n",
    "            px = current_snapshot[current_snapshot['symbol_enc'] == symbol]['px'].iloc[0]\n",
    "            prices[symbol] = px\n",
    "        for symbol in short_symbols:\n",
    "            px = current_snapshot[current_snapshot['symbol_enc'] == symbol]['px'].iloc[0]\n",
    "            prices[symbol] = px\n",
    "\n",
    "        rebalance_signals[t] = {'long': long_symbols, 'short': short_symbols, 'prices': prices}\n",
    "\n",
    "# --- 构建调仓周期内的持仓和计算周期收益 ---\n",
    "period_results = []\n",
    "all_positions_by_period = []\n",
    "\n",
    "current_long_positions = {}  # {symbol: open_price}\n",
    "current_short_positions = {} # {symbol: open_price}\n",
    "\n",
    "for i in tqdm(range(len(rebalance_times)), desc=\"Calculating Period Returns\"):\n",
    "    start_time = rebalance_times[i]\n",
    "    end_time = rebalance_times[i+1] if i + 1 < len(rebalance_times) else timestamps_sorted[-1]\n",
    "\n",
    "    # 获取当前周期的数据快照\n",
    "    period_data = bt_df[(bt_df['dt'] >= start_time) & (bt_df['dt'] <= end_time)].copy()\n",
    "    if period_data.empty:\n",
    "        # 如果当前时间段没有数据，则跳过\n",
    "        continue\n",
    "\n",
    "    # 获取当前时间点（周期开始）的价格快照，用于调仓决策\n",
    "    current_moment_prices = bt_df[bt_df['dt'] == start_time].set_index('symbol_enc')['px'].to_dict()\n",
    "    current_moment_preds = bt_df[bt_df['dt'] == start_time].set_index('symbol_enc')['predicted_prob'].to_dict()\n",
    "\n",
    "    # 复制上一个周期的持仓，用于计算交易费用\n",
    "    prev_long_symbols_for_cost = list(current_long_positions.keys())\n",
    "    prev_short_symbols_for_cost = list(current_short_positions.keys())\n",
    "\n",
    "    # --- Step 1: 检查并处理单币种止损 ---\n",
    "    # 在调仓之前，先处理已有的持仓是否触及止损\n",
    "    symbols_to_close = {'long': [], 'short': []}\n",
    "    current_period_transaction_cost = 0.0 # 用于累加本周期内的所有交易成本\n",
    "\n",
    "    # 遍历现有长仓检查止损\n",
    "    for symbol, open_px in list(current_long_positions.items()): # 使用list()避免在迭代时修改字典\n",
    "        current_px = current_moment_prices.get(symbol)\n",
    "        if current_px is not None and open_px is not None and (open_px - current_px) / open_px >= STOP_LOSS_PERCENT:\n",
    "            # 触发止损\n",
    "            del current_long_positions[symbol]\n",
    "            symbols_to_close['long'].append(symbol)\n",
    "            current_period_transaction_cost += TRANSACTION_COST_PER_TRADE * 2 # 开仓一次，平仓一次，所以是2\n",
    "\n",
    "            # print(f\"Stop-loss triggered for LONG {symbol} at {start_time.strftime('%Y-%m-%d %H:%M')}. Loss: {(open_px - current_px) / open_px:.2%}\")\n",
    "\n",
    "            # 联动平仓最弱的空头仓位\n",
    "            if current_short_positions:\n",
    "                # 找到当前所有空头品种的预测值，选择预测值最高的（最不看跌的，即最弱的空头）\n",
    "                weakest_short_symbol = None\n",
    "                highest_pred_for_short = -float('inf')\n",
    "                \n",
    "                # 遍历当前空头持仓，结合最新预测值来判断哪个是“最弱”的空头\n",
    "                # “最弱”的空头意味着其看跌倾向最不明显，或者甚至开始看涨了\n",
    "                for s in current_short_positions.keys():\n",
    "                    pred_val = current_moment_preds.get(s)\n",
    "                    if pred_val is not None and pred_val > highest_pred_for_short:\n",
    "                        highest_pred_for_short = pred_val\n",
    "                        weakest_short_symbol = s\n",
    "                \n",
    "                if weakest_short_symbol:\n",
    "                    del current_short_positions[weakest_short_symbol]\n",
    "                    symbols_to_close['short'].append(weakest_short_symbol)\n",
    "                    current_period_transaction_cost += TRANSACTION_COST_PER_TRADE * 2 # 联动平仓也算费用\n",
    "                    print(f\"  -> Linkage: Closed weakest SHORT {weakest_short_symbol} to rebalance.\")\n",
    "            \n",
    "    # 遍历现有短仓检查止损\n",
    "    for symbol, open_px in list(current_short_positions.items()):\n",
    "        current_px = current_moment_prices.get(symbol)\n",
    "        if current_px is not None and open_px is not None and (current_px - open_px) / open_px >= STOP_LOSS_PERCENT:\n",
    "            # 触发止损\n",
    "            del current_short_positions[symbol]\n",
    "            symbols_to_close['short'].append(symbol)\n",
    "            current_period_transaction_cost += TRANSACTION_COST_PER_TRADE * 2\n",
    "\n",
    "            # print(f\"Stop-loss triggered for SHORT {symbol} at {start_time.strftime('%Y-%m-%d %H:%M')}. Loss: {(current_px - open_px) / open_px:.2%}\")\n",
    "\n",
    "            # 联动平仓最弱的多头仓位\n",
    "            if current_long_positions:\n",
    "                # 找到当前所有多头品种的预测值，选择预测值最低的（最不看涨的，即最弱的多头）\n",
    "                weakest_long_symbol = None\n",
    "                lowest_pred_for_long = float('inf')\n",
    "\n",
    "                # 遍历当前多头持仓，结合最新预测值来判断哪个是“最弱”的多头\n",
    "                # “最弱”的多头意味着其看涨倾向最不明显，或者甚至开始看跌了\n",
    "                for s in current_long_positions.keys():\n",
    "                    pred_val = current_moment_preds.get(s)\n",
    "                    if pred_val is not None and pred_val < lowest_pred_for_long:\n",
    "                        lowest_pred_for_long = pred_val\n",
    "                        weakest_long_symbol = s\n",
    "\n",
    "                if weakest_long_symbol:\n",
    "                    del current_long_positions[weakest_long_symbol]\n",
    "                    symbols_to_close['long'].append(weakest_long_symbol)\n",
    "                    current_period_transaction_cost += TRANSACTION_COST_PER_TRADE * 2\n",
    "                    print(f\"  -> Linkage: Closed weakest LONG {weakest_long_symbol} to rebalance.\")\n",
    "\n",
    "\n",
    "    # --- Step 2: 根据调仓信号更新持仓 ---\n",
    "    # 获取本周期的目标持仓\n",
    "    target_long_symbols = rebalance_signals[start_time]['long']\n",
    "    target_short_symbols = rebalance_signals[start_time]['short']\n",
    "    target_prices = rebalance_signals[start_time]['prices'] # 目标开仓价格\n",
    "\n",
    "    # 平仓不再持有的仓位\n",
    "    for symbol in list(current_long_positions.keys()):\n",
    "        if symbol not in target_long_symbols:\n",
    "            del current_long_positions[symbol]\n",
    "            current_period_transaction_cost += TRANSACTION_COST_PER_TRADE # 平仓费用\n",
    "            symbols_to_close['long'].append(symbol) # 记录平仓\n",
    "\n",
    "    for symbol in list(current_short_positions.keys()):\n",
    "        if symbol not in target_short_symbols:\n",
    "            del current_short_positions[symbol]\n",
    "            current_period_transaction_cost += TRANSACTION_COST_PER_TRADE # 平仓费用\n",
    "            symbols_to_close['short'].append(symbol) # 记录平仓\n",
    "\n",
    "    # 开仓新的仓位\n",
    "    for symbol in target_long_symbols:\n",
    "        if symbol not in current_long_positions:\n",
    "            current_long_positions[symbol] = target_prices.get(symbol)\n",
    "            current_period_transaction_cost += TRANSACTION_COST_PER_TRADE # 开仓费用\n",
    "\n",
    "    for symbol in target_short_symbols:\n",
    "        if symbol not in current_short_positions:\n",
    "            current_short_positions[symbol] = target_prices.get(symbol)\n",
    "            current_period_transaction_cost += TRANSACTION_COST_PER_TRADE # 开仓费用\n",
    "\n",
    "    # --- Step 3: 计算本周期的策略收益 (毛收益) ---\n",
    "    gross_period_log_return = 0.0\n",
    "    if not current_long_positions and not current_short_positions: # 如果本周期开始和结束都没有持仓\n",
    "        gross_period_log_return = 0.0\n",
    "    else:\n",
    "        long_portfolio_log_return = 0.0\n",
    "        for symbol, open_px in current_long_positions.items():\n",
    "            try:\n",
    "                # 获取本周期末的价格\n",
    "                long_end_px = period_data[(period_data['dt'] == end_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                # 这里应该用当前周期开始的价格（start_time的价格）来计算周期收益，而不是开仓价格\n",
    "                long_start_px = period_data[(period_data['dt'] == start_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                long_portfolio_log_return += (np.log(long_end_px) - np.log(long_start_px))\n",
    "            except IndexError:\n",
    "                # 如果这个品种在当前周期数据中缺失，则不计算其收益\n",
    "                long_portfolio_log_return += 0.0\n",
    "                pass\n",
    "\n",
    "        short_portfolio_log_return = 0.0\n",
    "        for symbol, open_px in current_short_positions.items():\n",
    "            try:\n",
    "                short_end_px = period_data[(period_data['dt'] == end_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                short_start_px = period_data[(period_data['dt'] == start_time) & (period_data['symbol_enc'] == symbol)]['px'].iloc[0]\n",
    "                short_portfolio_log_return += (np.log(short_end_px) - np.log(short_start_px))\n",
    "            except IndexError:\n",
    "                short_portfolio_log_return += 0.0\n",
    "                pass\n",
    "\n",
    "        num_active_positions = len(current_long_positions) + len(current_short_positions)\n",
    "        if num_active_positions > 0:\n",
    "            gross_period_log_return = (long_portfolio_log_return - short_portfolio_log_return) / num_active_positions\n",
    "        else:\n",
    "            gross_period_log_return = 0.0\n",
    "\n",
    "    net_period_log_return = gross_period_log_return - current_period_transaction_cost\n",
    "\n",
    "    # --- 记录当前调仓周期所有品种的持仓状态 (用于热力图) ---\n",
    "    all_unique_symbols = bt_df['symbol_enc'].unique()\n",
    "    current_period_positions_for_heatmap = {symbol: 0 for symbol in all_unique_symbols}\n",
    "\n",
    "    for symbol in current_long_positions.keys():\n",
    "        current_period_positions_for_heatmap[symbol] = 1\n",
    "\n",
    "    for symbol in current_short_positions.keys():\n",
    "        if current_period_positions_for_heatmap[symbol] != 1: # 避免与多头冲突\n",
    "            current_period_positions_for_heatmap[symbol] = -1\n",
    "\n",
    "    all_positions_by_period.append({'dt': start_time, **current_period_positions_for_heatmap})\n",
    "\n",
    "\n",
    "    period_results.append({\n",
    "        'dt': start_time,\n",
    "        'gross_strategy_log_return': gross_period_log_return,\n",
    "        'transaction_cost': current_period_transaction_cost, # 本周期总费用\n",
    "        'net_strategy_log_return': net_period_log_return,\n",
    "        'num_long_positions': len(current_long_positions),\n",
    "        'num_short_positions': len(current_short_positions),\n",
    "        'long_symbols_list': list(current_long_positions.keys()),\n",
    "        'short_symbols_list': list(current_short_positions.keys())\n",
    "    })\n",
    "\n",
    "# 将周期结果转换为 DataFrame\n",
    "strategy_results_df = pd.DataFrame(period_results).set_index('dt')\n",
    "\n",
    "# --- 准备持仓热力图数据 ---\n",
    "positions_heatmap_df = pd.DataFrame(all_positions_by_period).set_index('dt')\n",
    "positions_heatmap_df = positions_heatmap_df[sorted(positions_heatmap_df.columns)]\n",
    "\n",
    "\n",
    "# --- 绩效指标函数 (与之前相同) ---\n",
    "def perf_stats(return_series, periods_per_year):\n",
    "    if return_series.empty:\n",
    "        return {\n",
    "            'Cumulative Return': np.nan, 'Annualized Return': np.nan,\n",
    "            'Annualized Volatility': np.nan, 'Sharpe Ratio': np.nan, 'Max Drawdown': np.nan\n",
    "        }\n",
    "\n",
    "    cum_ret = return_series.cumsum().apply(np.exp)\n",
    "    total_return = cum_ret.iloc[-1] - 1\n",
    "\n",
    "    num_periods = len(return_series)\n",
    "    if num_periods > 0:\n",
    "        ann_return = (cum_ret.iloc[-1])**(periods_per_year / num_periods) - 1\n",
    "    else:\n",
    "        ann_return = np.nan\n",
    "\n",
    "    ann_vol = return_series.std() * np.sqrt(periods_per_year)\n",
    "    sharpe = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "    running_max = cum_ret.cummax()\n",
    "    drawdown = (cum_ret - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    return {\n",
    "        'Cumulative Return': total_return,\n",
    "        'Annualized Return': ann_return,\n",
    "        'Annualized Volatility': ann_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Max Drawdown': max_dd\n",
    "    }\n",
    "\n",
    "# --- 计算和展示绩效 ---\n",
    "periods_per_year_for_annualization = (365 * 24 * 60) / (N_INTERVAL * 10) # 假设10ms一个bar\n",
    "\n",
    "print(\"\\n--- Strategy Performance Statistics (Gross) ---\")\n",
    "gross_stats = perf_stats(strategy_results_df['gross_strategy_log_return'], periods_per_year_for_annualization)\n",
    "print(pd.Series(gross_stats))\n",
    "\n",
    "print(\"\\n--- Strategy Performance Statistics (Net of Costs) ---\")\n",
    "net_stats = perf_stats(strategy_results_df['net_strategy_log_return'], periods_per_year_for_annualization)\n",
    "print(pd.Series(net_stats))\n",
    "\n",
    "print(f\"\\nTotal Transaction Cost (Sum of individual costs): {strategy_results_df['transaction_cost'].sum():.6f}\")\n",
    "\n",
    "# --- 绘制图表 (使用低饱和度配色) ---\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 22), sharex=False, gridspec_kw={'height_ratios': [0.35, 0.2, 0.2, 0.25]})\n",
    "\n",
    "# 定义低饱和度颜色\n",
    "COLOR_GROSS_RETURN = sns.color_palette(\"Paired\")[1]\n",
    "COLOR_NET_RETURN = sns.color_palette(\"Paired\")[3]\n",
    "COLOR_TRANSACTION_COST = sns.color_palette(\"Paired\")[5]\n",
    "COLOR_LONG_POSITIONS = sns.color_palette(\"Paired\")[7]\n",
    "COLOR_SHORT_POSITIONS = sns.color_palette(\"Paired\")[9]\n",
    "\n",
    "# 热力图颜色映射 (低饱和度 RdBu)\n",
    "HEATMAP_CMAP = sns.diverging_palette(240, 10, as_cmap=True, s=70, l=60, sep=1)\n",
    "\n",
    "# 设置图表背景风格 (可选，例如设置为白色背景)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# 子图1: 累计收益 (毛收益 vs. 净收益)\n",
    "strategy_results_df['gross_strategy_log_return'].cumsum().apply(np.exp).plot(ax=axes[0], label='Cumulative Gross Return', color=COLOR_GROSS_RETURN)\n",
    "strategy_results_df['net_strategy_log_return'].cumsum().apply(np.exp).plot(ax=axes[0], label='Cumulative Net Return', color=COLOR_NET_RETURN)\n",
    "axes[0].set_title(f\"Cumulative Strategy Returns (Rebalance every {N_INTERVAL} bars, Long {N_LONG}, Short {N_SHORT})\")\n",
    "axes[0].set_ylabel(\"Cumulative Return\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, linestyle=':', alpha=0.7)\n",
    "axes[0].set_xlabel(\"\")\n",
    "\n",
    "# 子图2: 累计手续费消耗\n",
    "strategy_results_df['transaction_cost'].cumsum().plot(ax=axes[1], label='Cumulative Transaction Cost', color=COLOR_TRANSACTION_COST)\n",
    "axes[1].set_title(\"Cumulative Transaction Cost Over Time\")\n",
    "axes[1].set_ylabel(\"Total Cost\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, linestyle=':', alpha=0.7)\n",
    "axes[1].set_xlabel(\"\")\n",
    "\n",
    "# 子图3: 持仓数量变化 (保留，作为快速概览)\n",
    "strategy_results_df['num_long_positions'].plot(ax=axes[2], label='Number of Long Positions', color=COLOR_LONG_POSITIONS, drawstyle='steps-post')\n",
    "strategy_results_df['num_short_positions'].plot(ax=axes[2], label='Number of Short Positions', color=COLOR_SHORT_POSITIONS, drawstyle='steps-post')\n",
    "axes[2].set_title(\"Number of Long and Short Positions Over Time (Overview)\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "axes[2].set_xlabel(\"\")\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, linestyle=':', alpha=0.7)\n",
    "axes[2].set_ylim(bottom=0)\n",
    "\n",
    "# 子图4: 详细持仓热力图\n",
    "if not positions_heatmap_df.empty:\n",
    "    sns.heatmap(\n",
    "        positions_heatmap_df.T,\n",
    "        cmap=HEATMAP_CMAP,\n",
    "        cbar_kws={'ticks': [-1, 0, 1], 'label': 'Position Status (-1: Short, 0: None, 1: Long)'},\n",
    "        ax=axes[3],\n",
    "        yticklabels=True,\n",
    "        xticklabels=True,\n",
    "        linewidths=0.5,\n",
    "        linecolor='lightgray'\n",
    "    )\n",
    "    axes[3].set_title(\"Detailed Position Status Heatmap (Per Symbol)\")\n",
    "    axes[3].set_xlabel(\"Rebalance Timestamp\")\n",
    "    axes[3].set_ylabel(\"Symbol\")\n",
    "    \n",
    "    # 调整x轴刻度标签，避免重叠\n",
    "    num_ticks = 10 \n",
    "    if len(positions_heatmap_df.index) > num_ticks:\n",
    "        tick_interval = len(positions_heatmap_df.index) // num_ticks\n",
    "        axes[3].set_xticks(np.arange(0, len(positions_heatmap_df.index), tick_interval))\n",
    "        axes[3].set_xticklabels(positions_heatmap_df.index[::tick_interval].strftime('%Y-%m-%d %H:%M'))\n",
    "    else:\n",
    "        axes[3].set_xticklabels(positions_heatmap_df.index.strftime('%Y-%m-%d %H:%M'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50d913-73e9-4abe-8ec6-20d9b974139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# import seaborn as sns # 用于绘制热力图\n",
    "\n",
    "# # --- 假设 full_df 已经包含以下列 ---\n",
    "# # - 'timestamp'（时间戳，可转为 datetime）\n",
    "# # - 'symbol_enc'（币种编码）\n",
    "# # - 'px'（当期价格）\n",
    "# # - 'predicted_prob'（模型预测的概率，越大表示越好）\n",
    "\n",
    "# # --- 配置参数 ---\n",
    "# # 注意：你需要在这里定义或加载 full_df。\n",
    "# # 示例：\n",
    "# # full_df = pd.read_csv('your_data.csv')\n",
    "# # full_df['timestamp'] = pd.to_datetime(full_df['timestamp'], unit='ms') # 确保timestamp是datetime类型\n",
    "\n",
    "# # 假设 full_df 已准备好\n",
    "# bt_df = full_df \n",
    "\n",
    "\n",
    "# N_INTERVAL = N # 调仓周期，每 N_INTERVAL 个时间戳调仓一次\n",
    "# N_LONG = 4         # 做多的品种数量\n",
    "# N_SHORT = 4        # 做空的品种数量\n",
    "\n",
    "# # 交易费用率 (例如，万分之二，双边费用)\n",
    "# TRANSACTION_FEE_RATE  = 0.0002 / (N_LONG + N_SHORT)\n",
    "\n",
    "# # 新增：单币种止损参数\n",
    "# STOP_LOSS_PERCENT = 0.15 # 单币种止损百分比，例如 0.15 表示 15% 的亏损止损\n",
    "\n",
    "# # 初始资金\n",
    "# INITIAL_EQUITY = 100000 \n",
    "\n",
    "# # --- 数据预处理 ---\n",
    "# bt_df['dt'] = pd.to_datetime(bt_df['timestamp'], unit='ms')\n",
    "# bt_df = bt_df.sort_values(['dt', 'symbol_enc']).reset_index(drop=True)\n",
    "\n",
    "# # 获取所有独立的 Bar 时间戳\n",
    "# all_bar_times = bt_df['dt'].drop_duplicates().sort_values().to_list()\n",
    "\n",
    "# # 识别调仓时间点\n",
    "# # 这里假设 rebalance_times 仍然是预先知道的，或者在循环中动态计算\n",
    "# rebalance_times_set = set(all_bar_times[::N_INTERVAL]) # 用 set 提高查找效率\n",
    "\n",
    "# # --- 识别多空信号（在每个调仓时间点）---\n",
    "# # 提前计算所有调仓点的信号，避免在主循环中重复计算\n",
    "# precomputed_rebalance_signals = {}\n",
    "# for t in tqdm(rebalance_times_set, desc=\"Precomputing Rebalance Signals\"):\n",
    "#     current_snapshot = bt_df[bt_df['dt'] == t].copy()\n",
    "#     if current_snapshot.empty:\n",
    "#         precomputed_rebalance_signals[t] = {'long': [], 'short': [], 'prices': {}}\n",
    "#         continue\n",
    "\n",
    "#     sorted_by_prediction = current_snapshot.sort_values(by='predicted_prob', ascending=False)\n",
    "    \n",
    "#     long_symbols = sorted_by_prediction.head(N_LONG)['symbol_enc'].tolist()\n",
    "#     short_symbols_potential = sorted_by_prediction.tail(N_SHORT)['symbol_enc'].tolist()\n",
    "#     short_symbols = [s for s in short_symbols_potential if s not in long_symbols]\n",
    "\n",
    "#     # 强制多空同时开仓（如果某个方向数量不足，则都为空）\n",
    "#     if not long_symbols or not short_symbols or len(long_symbols) < N_LONG or len(short_symbols) < N_SHORT:\n",
    "#         precomputed_rebalance_signals[t] = {'long': [], 'short': [], 'prices': {}}\n",
    "#     else:\n",
    "#         prices = {}\n",
    "#         for symbol in long_symbols:\n",
    "#             px = current_snapshot[current_snapshot['symbol_enc'] == symbol]['px'].iloc[0]\n",
    "#             prices[symbol] = px\n",
    "#         for symbol in short_symbols:\n",
    "#             px = current_snapshot[current_snapshot['symbol_enc'] == symbol]['px'].iloc[0]\n",
    "#             prices[symbol] = px\n",
    "#         precomputed_rebalance_signals[t] = {'long': long_symbols, 'short': short_symbols, 'prices': prices}\n",
    "\n",
    "\n",
    "# # --- 回测主循环 (逐 Bar 模拟) ---\n",
    "# # current_long_positions: {symbol: {'open_price': price, 'size': amount, 'realized_pnl_at_open': 0}}\n",
    "# # current_short_positions: {symbol: {'open_price': price, 'size': amount, 'realized_pnl_at_open': 0}}\n",
    "# # 这里我们采用等资金量分配，假设每个多头/空头仓位占用 1 / (N_LONG + N_SHORT) 的资金\n",
    "# # 这样每个仓位的金额就是 INITIAL_EQUITY / (N_LONG + N_SHORT)\n",
    "# # 为了简化，我们假设每笔交易只开仓 1 份，盈亏按百分比计算，总回报最终指数化\n",
    "# # 如果要精确的浮动收益，需要记录每个仓位的持仓股数或价值\n",
    "# current_long_positions = {}  # {symbol: open_price}\n",
    "# current_short_positions = {} # {symbol: open_price}\n",
    "\n",
    "# # 记录绩效的列表\n",
    "# daily_results = []\n",
    "# all_positions_for_heatmap = []\n",
    "\n",
    "# current_equity = INITIAL_EQUITY\n",
    "# realized_pnl = 0.0 # 已实现盈亏\n",
    "# transaction_costs_total = 0.0\n",
    "\n",
    "# for i, current_bar_time in enumerate(tqdm(all_bar_times, desc=\"Running Backtest (Bar by Bar)\")):\n",
    "#     # 获取当前 Bar 的数据快照\n",
    "#     current_bar_data = bt_df[bt_df['dt'] == current_bar_time].copy()\n",
    "#     if current_bar_data.empty:\n",
    "#         continue # 跳过没有数据的 Bar\n",
    "\n",
    "#     current_prices_dict = current_bar_data.set_index('symbol_enc')['px'].to_dict()\n",
    "#     current_preds_dict = current_bar_data.set_index('symbol_enc')['predicted_prob'].to_dict()\n",
    "\n",
    "#     bar_realized_pnl = 0.0 # 本 Bar 内实现的盈亏\n",
    "#     bar_transaction_cost = 0.0 # 本 Bar 内发生的交易费用\n",
    "\n",
    "#     # --- Step 1: 检查并处理单币种止损 (在每个 Bar 开始时检查) ---\n",
    "#     # !!! 注意：这里止损是基于开仓价格的百分比，且一旦触发，立即平仓\n",
    "#     # 这会导致止损平仓的费用和盈亏立即计入本 Bar 的 realized_pnl\n",
    "    \n",
    "#     # 临时列表，记录要删除的止损品种\n",
    "#     stop_loss_triggered_long = []\n",
    "#     stop_loss_triggered_short = []\n",
    "\n",
    "#     for symbol, open_px in list(current_long_positions.items()):\n",
    "#         current_px = current_prices_dict.get(symbol)\n",
    "#         if current_px is not None and open_px is not None:\n",
    "#             if (open_px - current_px) / open_px >= STOP_LOSS_PERCENT: # 达到止损点\n",
    "#                 # 计算已实现盈亏 (假设每笔交易等资金量，按对数收益率加总)\n",
    "#                 bar_realized_pnl += (np.log(current_px) - np.log(open_px)) # 亏损为负值\n",
    "#                 bar_transaction_cost += TRANSACTION_FEE_RATE * 2 # 开仓 + 平仓\n",
    "#                 stop_loss_triggered_long.append(symbol)\n",
    "#                 # print(f\"  SL: LONG {symbol} at {current_bar_time.strftime('%Y-%m-%d %H:%M')} (Open: {open_px:.4f}, Current: {current_px:.4f})\")\n",
    "\n",
    "#                 # 联动平仓最弱的空头仓位\n",
    "#                 if current_short_positions:\n",
    "#                     weakest_short_symbol = None\n",
    "#                     highest_pred_for_short = -float('inf')\n",
    "#                     for s in current_short_positions.keys():\n",
    "#                         pred_val = current_preds_dict.get(s)\n",
    "#                         if pred_val is not None and pred_val > highest_pred_for_short:\n",
    "#                             highest_pred_for_short = pred_val\n",
    "#                             weakest_short_symbol = s\n",
    "                    \n",
    "#                     if weakest_short_symbol and weakest_short_symbol not in stop_loss_triggered_short: # 避免重复平仓\n",
    "#                         bar_realized_pnl -= (np.log(current_prices_dict.get(weakest_short_symbol, current_short_positions[weakest_short_symbol])) - np.log(current_short_positions[weakest_short_symbol]))\n",
    "#                         bar_transaction_cost += TRANSACTION_FEE_RATE * 2 # 联动平仓也算费用\n",
    "#                         stop_loss_triggered_short.append(weakest_short_symbol)\n",
    "#                         # print(f\"    -> LINKAGE: Closed SHORT {weakest_short_symbol}\")\n",
    "            \n",
    "#     for symbol, open_px in list(current_short_positions.items()):\n",
    "#         current_px = current_prices_dict.get(symbol)\n",
    "#         if current_px is not None and open_px is not None:\n",
    "#             if (current_px - open_px) / open_px >= STOP_LOSS_PERCENT: # 达到止损点\n",
    "#                 # 计算已实现盈亏 (空头收益是负的，所以这里是减去)\n",
    "#                 bar_realized_pnl -= (np.log(current_px) - np.log(open_px)) # 亏损为负值\n",
    "#                 bar_transaction_cost += TRANSACTION_FEE_RATE * 2\n",
    "#                 stop_loss_triggered_short.append(symbol)\n",
    "#                 # print(f\"  SL: SHORT {symbol} at {current_bar_time.strftime('%Y-%m-%d %H:%M')} (Open: {open_px:.4f}, Current: {current_px:.4f})\")\n",
    "\n",
    "#                 # 联动平仓最弱的多头仓位\n",
    "#                 if current_long_positions:\n",
    "#                     weakest_long_symbol = None\n",
    "#                     lowest_pred_for_long = float('inf')\n",
    "#                     for s in current_long_positions.keys():\n",
    "#                         pred_val = current_preds_dict.get(s)\n",
    "#                         if pred_val is not None and pred_val < lowest_pred_for_long:\n",
    "#                             lowest_pred_for_long = pred_val\n",
    "#                             weakest_long_symbol = s\n",
    "                    \n",
    "#                     if weakest_long_symbol and weakest_long_symbol not in stop_loss_triggered_long: # 避免重复平仓\n",
    "#                         bar_realized_pnl += (np.log(current_prices_dict.get(weakest_long_symbol, current_long_positions[weakest_long_symbol])) - np.log(current_long_positions[weakest_long_symbol]))\n",
    "#                         bar_transaction_cost += TRANSACTION_FEE_RATE * 2\n",
    "#                         stop_loss_triggered_long.append(weakest_long_symbol)\n",
    "#                         # print(f\"    -> LINKAGE: Closed LONG {weakest_long_symbol}\")\n",
    "\n",
    "#     # 从持仓字典中移除止损和平仓的品种\n",
    "#     for symbol in stop_loss_triggered_long:\n",
    "#         if symbol in current_long_positions:\n",
    "#             del current_long_positions[symbol]\n",
    "#     for symbol in stop_loss_triggered_short:\n",
    "#         if symbol in current_short_positions:\n",
    "#             del current_short_positions[symbol]\n",
    "\n",
    "\n",
    "#     # --- Step 2: 检查是否为调仓时间点，并执行调仓 ---\n",
    "#     if current_bar_time in rebalance_times_set:\n",
    "#         # print(f\"Rebalancing at {current_bar_time.strftime('%Y-%m-%d %H:%M')}\")\n",
    "#         target_signals = precomputed_rebalance_signals.get(current_bar_time, {'long': [], 'short': [], 'prices': {}})\n",
    "#         target_long_symbols = target_signals['long']\n",
    "#         target_short_symbols = target_signals['short']\n",
    "#         target_prices = target_signals['prices']\n",
    "\n",
    "#         # 平仓不再持有的仓位 (除了止损平仓的)\n",
    "#         symbols_to_close_by_rebalance = {'long': [], 'short': []}\n",
    "#         for symbol in list(current_long_positions.keys()):\n",
    "#             if symbol not in target_long_symbols and symbol not in stop_loss_triggered_long: # 避免重复处理已止损的\n",
    "#                 bar_realized_pnl += (np.log(current_prices_dict.get(symbol, current_long_positions[symbol])) - np.log(current_long_positions[symbol]))\n",
    "#                 bar_transaction_cost += TRANSACTION_FEE_RATE # 平仓费用\n",
    "#                 del current_long_positions[symbol]\n",
    "#                 symbols_to_close_by_rebalance['long'].append(symbol)\n",
    "\n",
    "#         for symbol in list(current_short_positions.keys()):\n",
    "#             if symbol not in target_short_symbols and symbol not in stop_loss_triggered_short: # 避免重复处理已止损的\n",
    "#                 bar_realized_pnl -= (np.log(current_prices_dict.get(symbol, current_short_positions[symbol])) - np.log(current_short_positions[symbol]))\n",
    "#                 bar_transaction_cost += TRANSACTION_FEE_RATE # 平仓费用\n",
    "#                 del current_short_positions[symbol]\n",
    "#                 symbols_to_close_by_rebalance['short'].append(symbol)\n",
    "\n",
    "#         # 开仓新的仓位\n",
    "#         for symbol in target_long_symbols:\n",
    "#             if symbol not in current_long_positions:\n",
    "#                 open_px = target_prices.get(symbol)\n",
    "#                 if open_px is not None:\n",
    "#                     current_long_positions[symbol] = open_px\n",
    "#                     bar_transaction_cost += TRANSACTION_FEE_RATE # 开仓费用\n",
    "\n",
    "#         for symbol in target_short_symbols:\n",
    "#             if symbol not in current_short_positions:\n",
    "#                 open_px = target_prices.get(symbol)\n",
    "#                 if open_px is not None:\n",
    "#                     current_short_positions[symbol] = open_px\n",
    "#                     bar_transaction_cost += TRANSACTION_FEE_RATE # 开仓费用\n",
    "\n",
    "#     # --- Step 3: 计算本 Bar 的浮动收益和总净值 ---\n",
    "#     unrealized_pnl_this_bar = 0.0\n",
    "#     num_active_positions = 0\n",
    "    \n",
    "#     # 浮动盈亏计算：当前价格 vs. 开仓价格\n",
    "#     for symbol, open_px in current_long_positions.items():\n",
    "#         current_px = current_prices_dict.get(symbol)\n",
    "#         if current_px is not None and open_px is not None:\n",
    "#             unrealized_pnl_this_bar += (np.log(current_px) - np.log(open_px))\n",
    "#             num_active_positions += 1\n",
    "\n",
    "#     for symbol, open_px in current_short_positions.items():\n",
    "#         current_px = current_prices_dict.get(symbol)\n",
    "#         if current_px is not None and open_px is not None:\n",
    "#             unrealized_pnl_this_bar -= (np.log(current_px) - np.log(open_px)) # 空头反向计算\n",
    "\n",
    "#     # 为了将对数收益率转换为与初始资金挂钩的收益，这里需要一个权重或总对数收益\n",
    "#     # 假设每个持仓等资金量，总浮动对数收益率\n",
    "#     total_unrealized_log_return = unrealized_pnl_this_bar / num_active_positions if num_active_positions > 0 else 0.0\n",
    "\n",
    "#     # 将已实现盈亏和交易成本加到总净值中\n",
    "#     # 注意：这里的收益计算是一个简化，将所有盈亏视为直接加减到资金中\n",
    "#     # 更严谨的计算需要跟踪每笔交易的实际金额和股数\n",
    "    \n",
    "#     # 将对数收益率转换为百分比收益率，再乘以当前净值\n",
    "#     # 这部分是该bar内持仓的浮动收益率\n",
    "#     bar_net_return_percent = np.exp(total_unrealized_log_return) - 1 # 浮动收益率\n",
    "\n",
    "#     # 累加到总盈亏中，这里将每日的已实现盈亏和交易费用也体现在净值变化中\n",
    "#     # 简化：假设盈亏直接影响净值，不考虑保证金等复杂因素\n",
    "#     # daily_net_return = bar_realized_pnl + total_unrealized_log_return - bar_transaction_cost # 这个累加逻辑需要细化\n",
    "    \n",
    "#     # 更合理的做法：维护累计对数收益\n",
    "#     if len(daily_results) > 0:\n",
    "#         prev_cum_log_return = daily_results[-1]['cumulative_net_log_return']\n",
    "#     else:\n",
    "#         prev_cum_log_return = 0.0\n",
    "\n",
    "#     # 当前 Bar 的总对数收益 = (浮动对数收益率 + 本 Bar 已实现对数收益) - 本 Bar 交易成本\n",
    "#     # 注意这里的 bar_realized_pnl 已经是累计的对数收益\n",
    "#     # 这里的 bar_realized_pnl 是止损和平仓的对数收益，它是已经实现的\n",
    "#     # current_bar_total_log_return = total_unrealized_log_return + bar_realized_pnl - bar_transaction_cost\n",
    "    \n",
    "#     # 每次净值更新：(上一期的净值 + 本期已实现收益 - 本期交易成本) * (1 + 本期浮动收益率)\n",
    "#     # 这种方式更直观\n",
    "#     current_equity = current_equity * np.exp(total_unrealized_log_return) # 浮动部分\n",
    "\n",
    "#     # 将本 Bar 的已实现盈亏和交易成本直接计入 equity (这里简化处理，实际更复杂)\n",
    "#     # 这部分是额外的影响，因为止损和平仓发生在Bar内，不完全是Bar结束的浮动部分\n",
    "#     # 这里将已实现盈亏转换成百分比，再应用\n",
    "#     # 如果 bar_realized_pnl 是对数收益，直接加到 log_return 上更一致\n",
    "    \n",
    "#     # 更好的方式是维护一个总的策略对数收益率，以及一个浮动对数收益率\n",
    "#     # 已实现对数收益\n",
    "#     daily_realized_log_return = bar_realized_pnl \n",
    "    \n",
    "#     # 净对数收益 = 已实现收益 + 浮动收益 - 交易成本\n",
    "#     net_log_return_this_bar = daily_realized_log_return + total_unrealized_log_return - bar_transaction_cost\n",
    "    \n",
    "#     cumulative_net_log_return = prev_cum_log_return + net_log_return_this_bar\n",
    "#     current_equity = INITIAL_EQUITY * np.exp(cumulative_net_log_return)\n",
    "    \n",
    "#     realized_pnl += daily_realized_log_return # 累加总已实现盈亏\n",
    "#     transaction_costs_total += bar_transaction_cost # 累加总交易费用\n",
    "\n",
    "\n",
    "#     # --- 记录当前 Bar 的绩效 ---\n",
    "#     # 为热力图准备数据\n",
    "#     all_unique_symbols = bt_df['symbol_enc'].unique()\n",
    "#     current_bar_positions_for_heatmap = {symbol: 0 for symbol in all_unique_symbols}\n",
    "#     for symbol in current_long_positions.keys():\n",
    "#         current_bar_positions_for_heatmap[symbol] = 1\n",
    "#     for symbol in current_short_positions.keys():\n",
    "#         if current_bar_positions_for_heatmap[symbol] != 1:\n",
    "#             current_bar_positions_for_heatmap[symbol] = -1\n",
    "#     all_positions_for_heatmap.append({'dt': current_bar_time, **current_bar_positions_for_heatmap})\n",
    "\n",
    "\n",
    "#     daily_results.append({\n",
    "#         'dt': current_bar_time,\n",
    "#         'gross_log_return_this_bar': (daily_realized_log_return + total_unrealized_log_return), # 本Bar毛对数收益\n",
    "#         'net_log_return_this_bar': net_log_return_this_bar, # 本Bar净对数收益\n",
    "#         'bar_transaction_cost': bar_transaction_cost, # 本Bar产生的交易费用\n",
    "#         'cumulative_net_log_return': cumulative_net_log_return, # 累计净对数收益\n",
    "#         'current_equity': current_equity, # 当前净值\n",
    "#         'num_long_positions': len(current_long_positions),\n",
    "#         'num_short_positions': len(current_short_positions),\n",
    "#         'long_symbols_list': list(current_long_positions.keys()),\n",
    "#         'short_symbols_list': list(current_short_positions.keys())\n",
    "#     })\n",
    "\n",
    "# # 将每日结果转换为 DataFrame\n",
    "# strategy_results_df = pd.DataFrame(daily_results).set_index('dt')\n",
    "\n",
    "# # --- 准备持仓热力图数据 ---\n",
    "# positions_heatmap_df = pd.DataFrame(all_positions_for_heatmap).set_index('dt')\n",
    "# positions_heatmap_df = positions_heatmap_df[sorted(positions_heatmap_df.columns)]\n",
    "\n",
    "\n",
    "# # --- 绩效指标函数 (与之前相同) ---\n",
    "# def perf_stats(return_series, periods_per_year):\n",
    "#     if return_series.empty:\n",
    "#         return {\n",
    "#             'Cumulative Return': np.nan, 'Annualized Return': np.nan,\n",
    "#             'Annualized Volatility': np.nan, 'Sharpe Ratio': np.nan, 'Max Drawdown': np.nan\n",
    "#         }\n",
    "\n",
    "#     # 注意：这里传入的 return_series 应该是净对数收益，直接进行cumsum\n",
    "#     cum_ret = return_series.cumsum().apply(np.exp)\n",
    "#     total_return = cum_ret.iloc[-1] - 1\n",
    "\n",
    "#     num_periods = len(return_series)\n",
    "#     if num_periods > 0:\n",
    "#         # (1 + annual_return) ^ (num_periods / periods_per_year) = (1 + total_return)\n",
    "#         # (1 + annual_return) = (1 + total_return) ^ (periods_per_year / num_periods)\n",
    "#         ann_return = (cum_ret.iloc[-1])**(periods_per_year / num_periods) - 1\n",
    "#     else:\n",
    "#         ann_return = np.nan\n",
    "\n",
    "#     ann_vol = return_series.std() * np.sqrt(periods_per_year)\n",
    "#     sharpe = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "\n",
    "#     running_max = cum_ret.cummax()\n",
    "#     drawdown = (cum_ret - running_max) / running_max\n",
    "#     max_dd = drawdown.min()\n",
    "#     return {\n",
    "#         'Cumulative Return': total_return,\n",
    "#         'Annualized Return': ann_return,\n",
    "#         'Annualized Volatility': ann_vol,\n",
    "#         'Sharpe Ratio': sharpe,\n",
    "#         'Max Drawdown': max_dd\n",
    "#     }\n",
    "\n",
    "# # --- 计算和展示绩效 ---\n",
    "# # periods_per_year_for_annualization 现在基于每个 Bar 的频率\n",
    "# # 假设你的 Bar 间隔是 10 毫秒，那么每秒 100 个 Bar，每分钟 6000 个 Bar，每天 864000 个 Bar\n",
    "# # 如果你的 Bar 是 1 分钟，那么 periods_per_year = 365 * 24 * 60\n",
    "# # 请根据你的实际数据 Bar 间隔调整 periods_per_year_for_annualization\n",
    "# # 这里假设 Bar 是每分钟一个（60秒/1000ms * N_INTERVAL 调仓间隔）\n",
    "# # 如果 N_INTERVAL 是指 Bar 的数量，那么 periods_per_year_for_annualization 应该基于 Bar 的总数和总时长\n",
    "# # 最简单的方式是：总 Bar 数量 / 总年数 * Bar 间隔 / (1 分钟)\n",
    "# # 假设你的 `dt` 的时间粒度就是 Bar 的时间粒度。\n",
    "# # 比如如果 Bar 是 1分钟线，那么 periods_per_year_for_annualization = 365 * 24 * 60\n",
    "# # 如果 Bar 是 1秒线，那么 periods_per_year_for_annualization = 365 * 24 * 60 * 60\n",
    "# bar_frequency_in_minutes = (all_bar_times[1] - all_bar_times[0]).total_seconds() / 60\n",
    "# periods_per_year_for_annualization = (365 * 24 * 60) / bar_frequency_in_minutes\n",
    "\n",
    "\n",
    "# print(\"\\n--- Strategy Performance Statistics (Net of Costs) ---\")\n",
    "# # 传入 daily_results 中的 net_log_return_this_bar\n",
    "# net_stats = perf_stats(strategy_results_df['net_log_return_this_bar'], periods_per_year_for_annualization)\n",
    "# print(pd.Series(net_stats))\n",
    "\n",
    "# print(f\"\\nTotal Transaction Cost (Sum of individual costs): {transaction_costs_total:.6f}\") # 使用累加的总费用\n",
    "\n",
    "\n",
    "# # --- 绘制图表 (使用低饱和度配色) ---\n",
    "# fig, axes = plt.subplots(4, 1, figsize=(16, 22), sharex=False, gridspec_kw={'height_ratios': [0.35, 0.2, 0.2, 0.25]})\n",
    "\n",
    "# # 定义低饱和度颜色\n",
    "# COLOR_NET_RETURN = sns.color_palette(\"Paired\")[3]\n",
    "# COLOR_TRANSACTION_COST = sns.color_palette(\"Paired\")[5]\n",
    "# COLOR_LONG_POSITIONS = sns.color_palette(\"Paired\")[7]\n",
    "# COLOR_SHORT_POSITIONS = sns.color_palette(\"Paired\")[9]\n",
    "\n",
    "# # 热力图颜色映射 (低饱和度 RdBu)\n",
    "# HEATMAP_CMAP = sns.diverging_palette(240, 10, as_cmap=True, s=70, l=60, sep=1)\n",
    "\n",
    "# plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# # 子图1: 累计净收益 (现在是逐 Bar 的净值曲线)\n",
    "# # 直接绘制 equity curve\n",
    "# strategy_results_df['current_equity'].plot(ax=axes[0], label='Cumulative Net Equity', color=COLOR_NET_RETURN)\n",
    "# axes[0].set_title(f\"Cumulative Strategy Equity (Rebalance every {N_INTERVAL} bars, Long {N_LONG}, Short {N_SHORT})\")\n",
    "# axes[0].set_ylabel(\"Equity\")\n",
    "# axes[0].legend()\n",
    "# axes[0].grid(True, linestyle=':', alpha=0.7)\n",
    "# axes[0].set_xlabel(\"\")\n",
    "\n",
    "\n",
    "# # 子图2: 累计手续费消耗 (现在是逐 Bar 累加)\n",
    "# strategy_results_df['bar_transaction_cost'].cumsum().plot(ax=axes[1], label='Cumulative Transaction Cost', color=COLOR_TRANSACTION_COST)\n",
    "# axes[1].set_title(\"Cumulative Transaction Cost Over Time\")\n",
    "# axes[1].set_ylabel(\"Total Cost\")\n",
    "# axes[1].legend()\n",
    "# axes[1].grid(True, linestyle=':', alpha=0.7)\n",
    "# axes[1].set_xlabel(\"\")\n",
    "\n",
    "\n",
    "# # 子图3: 持仓数量变化 (现在是逐 Bar 记录)\n",
    "# strategy_results_df['num_long_positions'].plot(ax=axes[2], label='Number of Long Positions', color=COLOR_LONG_POSITIONS, drawstyle='steps-post')\n",
    "# strategy_results_df['num_short_positions'].plot(ax=axes[2], label='Number of Short Positions', color=COLOR_SHORT_POSITIONS, drawstyle='steps-post')\n",
    "# axes[2].set_title(\"Number of Long and Short Positions Over Time (Overview)\")\n",
    "# axes[2].set_ylabel(\"Count\")\n",
    "# axes[2].set_xlabel(\"\")\n",
    "# axes[2].legend()\n",
    "# axes[2].grid(True, linestyle=':', alpha=0.7)\n",
    "# axes[2].set_ylim(bottom=0)\n",
    "\n",
    "# # 子图4: 详细持仓热力图 (现在是逐 Bar 记录)\n",
    "# if not positions_heatmap_df.empty:\n",
    "#     # 调整热力图 X 轴刻度，避免过于密集\n",
    "#     x_ticks = np.linspace(0, len(positions_heatmap_df) - 1, min(10, len(positions_heatmap_df))).astype(int)\n",
    "#     x_labels = [positions_heatmap_df.index[i].strftime('%Y-%m-%d %H:%M') for i in x_ticks]\n",
    "\n",
    "#     sns.heatmap(\n",
    "#         positions_heatmap_df.T,\n",
    "#         cmap=HEATMAP_CMAP,\n",
    "#         cbar_kws={'ticks': [-1, 0, 1], 'label': 'Position Status (-1: Short, 0: None, 1: Long)'},\n",
    "#         ax=axes[3],\n",
    "#         yticklabels=True,\n",
    "#         xticklabels=x_labels, # 使用调整后的标签\n",
    "#         linewidths=0.5,\n",
    "#         linecolor='lightgray'\n",
    "#     )\n",
    "#     axes[3].set_title(\"Detailed Position Status Heatmap (Per Symbol)\")\n",
    "#     axes[3].set_xlabel(\"Bar Timestamp\")\n",
    "#     axes[3].set_ylabel(\"Symbol\")\n",
    "#     axes[3].set_xticks(x_ticks) # 应用调整后的刻度位置\n",
    "#     plt.setp(axes[3].get_xticklabels(), rotation=45, ha=\"right\") # 旋转标签\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0d9ac6d-2b44-468b-9ad9-8403aef23644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal, ROUND_DOWN, getcontext\n",
    "import logging\n",
    "import math\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def decimal_places(value: float) -> int:\n",
    "    \"\"\"从浮点数推断小数位数，例如 0.001 -> 3\"\"\"\n",
    "    try:\n",
    "        d = Decimal(str(value)).normalize()\n",
    "        return -d.as_tuple().exponent if d.as_tuple().exponent < 0 else 0\n",
    "    except:\n",
    "        return 6  # fallback 精度\n",
    "\n",
    "def calculate_position_quantity(\n",
    "    fixed_cash: float,\n",
    "    price: float,\n",
    "    min_size: float,\n",
    "    size_tick: float,\n",
    "    precision: int = None\n",
    ") -> str:\n",
    "    if fixed_cash <= 0 or price <= 0 or min_size <= 0 or size_tick <= 0:\n",
    "        logger.error(\"所有输入参数 (fixed_cash, price, min_size, size_tick) 必须是正数。\")\n",
    "        return \"0\"\n",
    "\n",
    "    if precision is None:\n",
    "        precision = decimal_places(size_tick)\n",
    "\n",
    "    getcontext().prec = precision + 6\n",
    "\n",
    "    fixed_cash_d = Decimal(str(fixed_cash))\n",
    "    price_d = Decimal(str(price))\n",
    "    min_size_d = Decimal(str(min_size))\n",
    "    size_tick_d = Decimal(str(size_tick))\n",
    "\n",
    "    raw_quantity = fixed_cash_d / price_d\n",
    "    if raw_quantity < min_size_d:\n",
    "        return \"0\"\n",
    "\n",
    "    quant_multiples = (raw_quantity / size_tick_d).to_integral_value(rounding=ROUND_DOWN)\n",
    "    final_quantity = quant_multiples * size_tick_d\n",
    "\n",
    "    if final_quantity < min_size_d:\n",
    "        logger.warning(f\"调整后数量 {final_quantity} 仍小于最小数量 {min_size}\")\n",
    "        return \"0\"\n",
    "\n",
    "    final_quantity_str = str(\n",
    "        final_quantity.quantize(Decimal(f\"1e-{precision}\"), rounding=ROUND_DOWN)\n",
    "    )\n",
    "\n",
    "    return final_quantity_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77d7e08f-c899-489d-8dd7-93fc614fe854",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;241m==\u001b[39m case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed: got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Test case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed. Result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mtest_calculate_position_quantity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 28\u001b[0m, in \u001b[0;36mtest_calculate_position_quantity\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m test_cases \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 正常情况\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed_cash\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize_tick\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10.000\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed_cash\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize_tick\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     23\u001b[0m ]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, case \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_cases, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     26\u001b[0m     result \u001b[38;5;241m=\u001b[39m calculate_position_quantity(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed_cash\u001b[39m\u001b[38;5;124m\"\u001b[39m], case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize_tick\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mcase\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;241m==\u001b[39m case[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed: got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Test case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passed. Result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'precision'"
     ]
    }
   ],
   "source": [
    "def test_calculate_position_quantity():\n",
    "    test_cases = [\n",
    "        # 正常情况\n",
    "        {\"fixed_cash\": 100, \"price\": 10, \"min_size\": 0.001, \"size_tick\": 0.001, \"expected\": \"10.000\"},\n",
    "        {\"fixed_cash\": 123.456, \"price\": 12.34, \"min_size\": 0.001, \"size_tick\": 0.01, \"precision\": 4, \"expected\": \"10.0000\"},\n",
    "        {\"fixed_cash\": 0.005, \"price\": 1, \"min_size\": 0.001, \"size_tick\": 0.0001, \"precision\": 6, \"expected\": \"0.005000\"},\n",
    "\n",
    "        # 边界：精确刚好 min_size\n",
    "        {\"fixed_cash\": 0.002, \"price\": 2, \"min_size\": 0.001, \"size_tick\": 0.001, \"precision\": 6, \"expected\": \"0.001000\"},\n",
    "\n",
    "        # 边界：略小于 min_size\n",
    "        {\"fixed_cash\": 0.0019, \"price\": 2, \"min_size\": 0.001, \"size_tick\": 0.001, \"precision\": 6, \"expected\": \"0\"},\n",
    "\n",
    "        # 精度截断测试\n",
    "        {\"fixed_cash\": 1, \"price\": 3, \"min_size\": 0.0001, \"size_tick\": 0.0001, \"precision\": 4, \"expected\": \"0.3333\"},  # 注意精度控制是四舍五入还是截断，这里是 ROUND_DOWN\n",
    "\n",
    "        # 精度与 tick 不匹配（tick 更粗）\n",
    "        {\"fixed_cash\": 1, \"price\": 3, \"min_size\": 0.01, \"size_tick\": 0.01, \"precision\": 4, \"expected\": \"0.33\"},\n",
    "\n",
    "        # 错误输入：负数\n",
    "        {\"fixed_cash\": -100, \"price\": 10, \"min_size\": 0.001, \"size_tick\": 0.001, \"precision\": 6, \"expected\": \"0\"},\n",
    "        {\"fixed_cash\": 100, \"price\": -10, \"min_size\": 0.001, \"size_tick\": 0.001, \"precision\": 6, \"expected\": \"0\"},\n",
    "    ]\n",
    "\n",
    "    for i, case in enumerate(test_cases, 1):\n",
    "        result = calculate_position_quantity(\n",
    "            case[\"fixed_cash\"], case[\"price\"],\n",
    "            case[\"min_size\"], case[\"size_tick\"], case[\"precision\"]\n",
    "        )\n",
    "        assert result == case[\"expected\"], f\"Test case {i} failed: got {result}, expected {case['expected']}\"\n",
    "        print(f\"✅ Test case {i} passed. Result: {result}\")\n",
    "\n",
    "test_calculate_position_quantity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcfcdd84-b7d8-4281-b558-cbe4f48f5060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fixed_cash': 200, 'price': 3861.7, 'min_size': 0.002, 'size_tick': 0.001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.051'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case =  {\"fixed_cash\": 200, \"price\": 3861.7, \"min_size\": 0.002, \"size_tick\": 0.001}\n",
    "print(case)\n",
    "calculate_position_quantity(\n",
    "            case[\"fixed_cash\"], case[\"price\"],\n",
    "            case[\"min_size\"], case[\"size_tick\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c977576-9d69-44d1-ae97-49031cdd9845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machine_learning)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
